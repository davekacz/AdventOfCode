{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "LinAlg_Python_Review_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jAVv-XYKo9-M",
        "C2J-dcNuo9-M",
        "m0_Ocr7Oo9-M",
        "WrSdA7jZo9-Y",
        "5OAFQ-NIo9-f",
        "AVP-Krxgo9-j",
        "NVPcXB4ko9-k",
        "shA98SAXo9-n",
        "IBxPEZG8o9-o",
        "z552bQXHo9-o",
        "-WaFX5-5o9-p",
        "ZKo0PJtVo9-0",
        "9LmLp750o9-3",
        "UjDo64q8o9--",
        "YefCSZPJo9_C",
        "glLrA3Dto9_S"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davekacz/AdventOfCode/blob/master/LinAlg_Python_Review_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOexS_sGo99-"
      },
      "source": [
        "## Linear Algebra & Python Reference Document "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou1s0Z2Bo9-E"
      },
      "source": [
        "Authored by Rice Paddies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uLzVBef6o9-F"
      },
      "source": [
        "# libraries \n",
        "from sympy import Matrix \n",
        "from scipy.linalg import lu\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "728hRFpio9-F"
      },
      "source": [
        "# Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kej2fd-Po9-F"
      },
      "source": [
        "We denote a set with an upper case italic letter such as <i>A</i>.  In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly we can say that vectors are sets of points while matrices are sets of vectors.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCcfknQrtJ0Y"
      },
      "source": [
        "![capture0](https://drive.google.com/uc?id=1RWs3xpXbdMzKYOojzMcuVMLzjfZVPYu8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCt7Fkf6o9-H"
      },
      "source": [
        "A subset can be viewed as a filtered down set.  Take as an example the set of all UFC cagefighters that I’ll denote as ***U***.  I can filter for *** “z is Asian” ***.  This assertion or condition *** S(x)*** is true for some members within the set of all UFC fighters and false for others. <br> \n",
        "\n",
        "Therefore, such a sentence, evaluated for all member of ***U***, generates a subset: the set of all Asian UFC fighters \n",
        "<center> $B =$ {$z ∈ U$ | z is Asian} </center> \n",
        "\n",
        "The vertical bar (|) reads as “such that”. Therefore, we can read the above expression as: all elements of z in U such that z is Asian. And that’s how we obtain the set B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT7iom1io9-I"
      },
      "source": [
        "# Ordered Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5zCjXRo9-I"
      },
      "source": [
        "An ordered pair is denoted as (X,Y), with X as the first coordinate and Y as the second coordinate. A valid ordered pair has the property that (X,Y) ≠ (Y,X).  Unordered pairs do not hold this property: X,Y = Y,X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqVTaaDuo9-I"
      },
      "source": [
        "# Relations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFScBIqgo9-J"
      },
      "source": [
        "In set theory, relations are defined as sets of ordered pairs and denoted as R: ***xRy***.  \n",
        "For any z ∈ R, there exist x and y such that z = (x,y).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2synoRPho9-J"
      },
      "source": [
        "Domain and Range:\n",
        "1. The domain is a set defined as: *** domain R = {x: for some y (xRy)} ***\n",
        "2. The range is a set defined as: *** range R = {y: for some x (x R y)} ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo0nUDapo9-K"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsHZmlrvo9-K"
      },
      "source": [
        "f: X → Y or f(x) = y <br>\n",
        "\n",
        "Matrices can be thought of as function action on vectors or other matrices.  In simplistic terms, machine learning can be described as the transformations or mappings from the domain onto the range of a function. The domain X is usually a vector (or set) of variables mapping onto a vector of target values.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwp79wero9-K"
      },
      "source": [
        "# Vectors & Matrices Part I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDylKBysu2-f"
      },
      "source": [
        "![1.5](https://drive.google.com/uc?id=1e-lsQCwT_c0L7P6pShV6Be6Xrg1cVA0G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5IMv-6ho9-L"
      },
      "source": [
        "Three types of vectors: \n",
        "1. geometric vectors \n",
        "2. polynomials \n",
        "3. elements of $R^n$ space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St8tHboDo9-L"
      },
      "source": [
        "### Setup Matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1D9Mwao9-L"
      },
      "source": [
        "Code for 3x1 matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sec-wzMo9-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e29bc0-c860-4480-a1c3-ebc90259b054"
      },
      "source": [
        "x=np.array([[5], [10], [15]])\n",
        "\n",
        "print(x)\n",
        "print ('--------')\n",
        "\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5]\n",
            " [10]\n",
            " [15]]\n",
            "--------\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EPoSrDT9o9-L"
      },
      "source": [
        "Code for 3x3 matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1dZSX4To9-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1e77ae-2ca3-4b42-e124-89e75007481d"
      },
      "source": [
        "x = np.array([[5, 6, -2], #row 1\n",
        "             [1, 0, 926], #row 2\n",
        "             [-3, 4, 6]]) #row 3\n",
        "              \n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  5   6  -2]\n",
            " [  1   0 926]\n",
            " [ -3   4   6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6zR8pkzo9-M"
      },
      "source": [
        "## Vector & Matrix Arithmetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAVv-XYKo9-M"
      },
      "source": [
        "### Vector Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRyPp0zGo9-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab0ccbe-e271-4162-f176-e376e4fc2f1f"
      },
      "source": [
        "x = np.array([[3], [6], [0]])\n",
        "y = np.array([[1], [5], [6]])\n",
        "\n",
        "x+y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4],\n",
              "       [11],\n",
              "       [ 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZ_NXyso9-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188073ce-d1d4-4e02-83c4-4bf16f9f566e"
      },
      "source": [
        "# alternative \n",
        "\n",
        "np.add(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4],\n",
              "       [11],\n",
              "       [ 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2J-dcNuo9-M"
      },
      "source": [
        "### Matrix Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9-I9yqeo9-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f102085f-fb76-445c-e71d-9bdb91ef22ed"
      },
      "source": [
        "x = np.array([[0,2],\n",
        "              [1,4]])\n",
        "y = np.array([[3,1],\n",
        "              [-3,2]])\n",
        "\n",
        "x+y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  3],\n",
              "       [-2,  6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0_Ocr7Oo9-M"
      },
      "source": [
        "### Multiply Vector w/Scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFHevn9io9-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8af094-399d-4e70-ed38-b807ca0d7af0"
      },
      "source": [
        "x = np.array([[4], [-9]])\n",
        "print (x)\n",
        "print ('-------')\n",
        "\n",
        "# multiply with scalar\n",
        "print (10*x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4]\n",
            " [-9]]\n",
            "-------\n",
            "[[ 40]\n",
            " [-90]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG1TMt0co9-N"
      },
      "source": [
        "### Multiply Matrix w/Scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RlSWrowo9-N"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQs8Ramvm2u"
      },
      "source": [
        "![capture1.5](https://drive.google.com/uc?id=1-EA6aRqMxisu_tsNVLq--oPluidj8pKs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZKyz81lo9-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557d9879-10df-4251-b7c7-46e8d5122728"
      },
      "source": [
        "# set 2x2 matrix\n",
        "x = np.array([[4, 0], [1, -9]])\n",
        "print (x)\n",
        "\n",
        "# multiply with scalar\n",
        "2*x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4  0]\n",
            " [ 1 -9]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  8,   0],\n",
              "       [  2, -18]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBcP_t6Bo9-N"
      },
      "source": [
        "### Linear Combinations of Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4G0xM2ho9-O"
      },
      "source": [
        "***Linear Combinations:*** taking the fundamental elements of a matrix (i.e. set of vectors) to generate a new object <br>\n",
        "\n",
        "There are only two legal operations with vectors in linear algebra:\n",
        "1. addition\n",
        "2. multiplication by numbers "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5VRgLq_o9-O"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU6SIOdHwNVm"
      },
      "source": [
        "![capture2](https://drive.google.com/uc?id=1G6U336ADOWOlMB4KrkEyoLIby1T2n83e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTsnSK9Go9-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a203cc-e2b4-4594-def2-652886b91505"
      },
      "source": [
        "x = np.array([[4, 2]])\n",
        "y = np.array([[5, 1]])\n",
        "\n",
        "print(x)\n",
        "print ('-----------')\n",
        "print(y)\n",
        "print ('-----------')\n",
        "\n",
        "print (3*x + -10*y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 2]]\n",
            "-----------\n",
            "[[5 1]]\n",
            "-----------\n",
            "[[-38  -4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUOPIctCo9-O"
      },
      "source": [
        "### Dot Product / Inner Product of Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRaly-z_o9-O"
      },
      "source": [
        "In machine learning, unless made explicit, we can safely assume that an inner product refers to the dot product.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2lOWsLlwpkA"
      },
      "source": [
        "![Capture2.3](https://drive.google.com/uc?id=1QHRMNvtKAWkg3fO3tqWT7z2V22iJriEE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnasLaLyo9-P"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGzj2Jc0w4ON"
      },
      "source": [
        "![Capture2.5](https://drive.google.com/uc?id=1t8joTs9l1EuHgAaPeZUwaABqfPJ_zbly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK3YF7lOo9-P"
      },
      "source": [
        "To multiply two vectors with dimensions (2x1) in Numpy, we need to ***transpose*** the first vector using the @ operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8aJotnSo9-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0a0f67-2be5-4692-9de1-ede1a4803eb8"
      },
      "source": [
        "x, y = np.array([[3], [-4]]), np.array([[6], [-6]])\n",
        "\n",
        "print(x)\n",
        "print ('-----------')\n",
        "print(y)\n",
        "\n",
        "# transpose matrix x\n",
        "print ('-----------')\n",
        "print(x.T)\n",
        "\n",
        "# dot product\n",
        "x.T @ y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3]\n",
            " [-4]]\n",
            "-----------\n",
            "[[ 6]\n",
            " [-6]]\n",
            "-----------\n",
            "[[ 3 -4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayy45ffro9-Q"
      },
      "source": [
        "### Dot Product / Inner Product of Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEltXqzto9-Q"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndklcbkkxIVL"
      },
      "source": [
        "![Capture3](https://drive.google.com/uc?id=1fykykUBj2YsZD0y_lQYMzjdDh7gFfuG-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6cSf-fYo9-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926855a6-06c8-49b8-c1ce-80f88ace6e71"
      },
      "source": [
        "# matrices in proper shape for dot product \n",
        "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "y = np.array([[7, 8], [9, 10], [11,12]])\n",
        "\n",
        "\n",
        "print(x)\n",
        "print ('-----------')\n",
        "print(y)\n",
        "print ('-----------')\n",
        "\n",
        "#dot product\n",
        "print(np.dot(x,y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "-----------\n",
            "[[ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]]\n",
            "-----------\n",
            "[[ 58  64]\n",
            " [139 154]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvdmHcfTo9-R"
      },
      "source": [
        "# Vector Space / Linear Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK5Zub1go9-R"
      },
      "source": [
        "***Vector space:*** set of proper vectors and all possible linear combinatios of the set. <br>\n",
        "\n",
        "Consider the vectors x and y and the scalars α and β. ***If we take all possible linear combinations of αx+βy we would obtain the span of such vectors.*** If our vectors x and y point into different directions in the 2-dimensional space, we get that the span(x,y) is equal to the entire 2-dimensional plane. <br>\n",
        "\n",
        "What would happen if the vectors point in the same direction? Vectors span a line as shown in the left-most image below. When two variables are “colinear” they are pointing in the same direction, hence they provide redundant information, so can drop one without information loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyEYJn3Bxb1O"
      },
      "source": [
        "![Capture3.5](https://drive.google.com/uc?id=1sxGV3JkgL_VzsKCQgJahCrLkYERfiYh9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3QHutZio9-R"
      },
      "source": [
        "# Vector Subspaces / Linear Subspaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80KVbFUwo9-S"
      },
      "source": [
        "A vector subspace (or linear subspace) is a vector space that lies within a larger vector space.  Consider a subspace S. For a vector to be a valid subspace it has to meet three conditions:\n",
        "1. contains the zero vector: ***0 ∈ S***\n",
        "2. closure under multiplication: ***∀α ∈ R → α×$s_i$ ∈ S***\n",
        "3. closure under addition: ***$∀s_i$ ∈ S → $s_1+s_2∈S$*** <br>\n",
        "\n",
        "\n",
        "Think of closure as being unable to “jump out” from one dimensional space into another.  A pair of vectors laying flat in the 2-dimensional space cannot (by either addition or multiplication) “jump out” into the 3-dimensional space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jORPryico9-S"
      },
      "source": [
        "# Linear Dependence & Independence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bcRcngjo9-T"
      },
      "source": [
        "A set of vectors is linearly dependent if at least one vector can be obtained as a linear combination of other vectors in the set.  A set of vectors is linearly independent if no vector can be obtained as a linear combination of other vectors in the set.  From a machine learning perspective, linearly dependent vectors contain redundant information whereas linearly independent vectors do not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWDMGxFxqFZ"
      },
      "source": [
        "![Capture4](https://drive.google.com/uc?id=1fz-J9-ky-1bMkq-wq0MDu90Qku8GUud2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUP3mz3go9-U"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnptrElTx8f2"
      },
      "source": [
        "![Capture8](https://drive.google.com/uc?id=1ABkL6yHOrkYk9AuJUwRdvc0XST9zv_Eo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeGgKptEo9-U"
      },
      "source": [
        "# Vector Null Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwkAbqZdo9-U"
      },
      "source": [
        "***Null space of a set of vectors:*** all linear combinations that “map” into the zero vector (0,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m5DJYGAy6gt"
      },
      "source": [
        "![Capture5](https://drive.google.com/uc?id=1DVe6h-XAaHhHEBkh727ezNQMvu2mpJzA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wHUT7ovo9-V"
      },
      "source": [
        "# Vector Norm / Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGmVVNkgo9-V"
      },
      "source": [
        "## Vector Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqq5x4jKo9-V"
      },
      "source": [
        "***Vector Norm***: (absolute value) length of vector  as distance between its “origin” and its “end”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45SMufIbzR7G"
      },
      "source": [
        "![Capture10](https://drive.google.com/uc?id=1YdX4UWKnogxKJsDjYy98M43-9e6I-_TI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAdl_2dAo9-W"
      },
      "source": [
        "## Manhattan Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKlebin9o9-W"
      },
      "source": [
        "***Manhattan Norm ($L_{1}$)***: gets its name in analogy to measuring distances while moving in Manhattan, NYC. Since Manhattan has a grid-shape, the distance between any two points is measured by moving in vertical and horizontals lines (instead of diagonals as in the Euclidean norm).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDZsm5zrzca6"
      },
      "source": [
        "![Capture11](https://drive.google.com/uc?id=1862EoiiZcFVmWMQljqpWGhjEBR9ysmZf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkDfv6iTo9-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe656e41-14c4-4d09-f2de-e86d417f51ec"
      },
      "source": [
        "x = np.array([[3],[-4]])\n",
        "\n",
        "np.linalg.norm(x, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6rvqqymo9-W"
      },
      "source": [
        "## Euclidean Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OnizlsZo9-X"
      },
      "source": [
        "****Euclidean Norm ($L_{2}$)***: euclidean norm is one of the most popular norms in machine learning. Referred to as “the norm” of a vector.  ***Distance*** stands for the euclidean distance or $L_2$ norm unless otherwise noted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGg0l_I1tii"
      },
      "source": [
        "![Capture12](https://drive.google.com/uc?id=1t03ZmlWL3xs8gUaiJV3BkZdVTo-C7QUG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEgMzSTeo9-X"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grUW0aU216tn"
      },
      "source": [
        "![Capture71](https://drive.google.com/uc?id=1UbJf1BR1fxTcdr_Kt3dgBhahDkFiHzW1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxbSOwkio9-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56b88f5-53f9-41c8-c79f-a6987cbdbf9a"
      },
      "source": [
        "# euclidean norm / magnitude of vector in 4 dimensions\n",
        "\n",
        "u = np.array([[1],[2], [-4], [1]])\n",
        "np.round(np.linalg.norm(u, 2), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmTVSKgno9-X"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EkogHd-2HjZ"
      },
      "source": [
        "![Capture72](https://drive.google.com/uc?id=1vlW7uVJngcq1h4wi0EUbJW3T18CC1Blx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NyDpRuwo9-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44254b75-8075-4938-d317-7f38ea477d92"
      },
      "source": [
        "# euclidean distance calculation in 3 dimensions \n",
        "\n",
        "u = np.array([3, -6, 2])\n",
        "v = np.array([1, 2, -1])\n",
        "\n",
        "distance = np.linalg.norm(u-v)\n",
        "np.round(distance, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrSdA7jZo9-Y"
      },
      "source": [
        "## Max Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC017BxIo9-Y"
      },
      "source": [
        "***Max Norm***: absolute value of the largest element in the vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JblEmKDo9-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c77d79-82fd-4581-9988-51ddaf13274a"
      },
      "source": [
        "x = np.array([[3], [-4], [1/20], [-6]])\n",
        "\n",
        "np.linalg.norm(x, np.inf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcxrZAb6o9-Z"
      },
      "source": [
        "## Unit Vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f58kjX4ho9-Z"
      },
      "source": [
        "***Unit Vector***: has length of 1; the unit vectors [0,1] and [1,0] can form together any other vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krKMH3yY2R7c"
      },
      "source": [
        "![Capture69](https://drive.google.com/uc?id=1dv2BzHFh82x1ALGG9wFS2bDKWrnb-7VY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYPJhKFc2dNC"
      },
      "source": [
        "![Capture68](https://drive.google.com/uc?id=1N1ljPtV10riX0hMj7Gzg8uZYujb-bYut)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGwOVq_Do9-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954cfd7f-318e-4e1a-ab9f-09ee6baf8c3a"
      },
      "source": [
        "# unit vector \n",
        "\n",
        "u = np.array([[2], [3], [5]])\n",
        "print (u)\n",
        "print ('----------------')\n",
        "\n",
        "u_hat = u * (1/(np.linalg.norm(u, 2))) # denominator is Euclidean norm\n",
        "print (np.round((u_hat), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2]\n",
            " [3]\n",
            " [5]]\n",
            "----------------\n",
            "[[0.324]\n",
            " [0.487]\n",
            " [0.811]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xshkSTIo9-a"
      },
      "source": [
        "# Angle Between Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PJ8qU6o9-a"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVDgHKGt2oWq"
      },
      "source": [
        "![Capture13](https://drive.google.com/uc?id=1kFCkt59vmrXWp0bMioRRRKEV2PZZd9QM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18X0ALko9-a"
      },
      "source": [
        "Compute the cos(θ) value between a pair of vectors: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPX4_QdKo9-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06d5fec-2f8c-452c-9275-a28ed8f4385b"
      },
      "source": [
        "x = np.array([[3], [4]])\n",
        "y = np.array([[4], [3]])\n",
        "\n",
        "\n",
        "print(x)\n",
        "print('-----')\n",
        "print (y)\n",
        "\n",
        "# solve for cos(θ)\n",
        "cos_theta = np.dot(x.T, y) / (np.linalg.norm(x,2)*np.linalg.norm(y,2))\n",
        "cos_theta\n",
        "\n",
        "print('-----')\n",
        "print(f'cos(θ) = {np.round(cos_theta, 3)}')\n",
        "\n",
        "# solve for θ value\n",
        "theta_rad = np.arccos(cos_theta)\n",
        "print('-----')\n",
        "print(f'θ = {np.round(theta_rad, 3)} radians')\n",
        "\n",
        "# convert angle from radians to degrees\n",
        "theta_deg = theta_rad * (180/np.pi)\n",
        "print('-----')\n",
        "print(f'θ = {np.round(theta_deg, 3)} degrees')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]\n",
            " [4]]\n",
            "-----\n",
            "[[4]\n",
            " [3]]\n",
            "-----\n",
            "cos(θ) = [[0.96]]\n",
            "-----\n",
            "θ = [[0.284]] radians\n",
            "-----\n",
            "θ = [[16.26]] degrees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMdM_4puo9-b"
      },
      "source": [
        "# Vector Orthogonality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU-t0uApo9-b"
      },
      "source": [
        "Orthogonality: perpendicularity of vectors in any number of dimensions; used interchangeably with “independence”\n",
        "1. $cos(θ) = 0$\n",
        "2. $u^Tv=0$\n",
        "3. $⟨x,y⟩ = 0$\n",
        "4. $u ⊥ v= 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHxaXe8u-3h7"
      },
      "source": [
        "![Capture15](https://drive.google.com/uc?id=1tOBoFbu2w88JbDcPrc5-q-dLZQHsIxPu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r4QYZo9o9-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e24863-6175-4305-cc72-34b4aee4e10c"
      },
      "source": [
        "# are the two vectors below orthogonal?  \n",
        "\n",
        "x = np.array([[4], [0]])\n",
        "y = np.array([[0], [4]])\n",
        "\n",
        "cos_theta = np.dot(x.T, y) / (np.linalg.norm(x,2) * np.linalg.norm(y,2))\n",
        "print(f'cos(θ) = {np.round(cos_theta)} so x and y vectors are orthogonal to each other')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cos(θ) = [[0.]] so x and y vectors are orthogonal to each other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sRE1BUOo9-c"
      },
      "source": [
        "# Matrices Part II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Ws-3S2o9-c"
      },
      "source": [
        "For matrices, there is no such thing as division. You can add, subtract, and multiply matrices but you cannot divide them.  Also, matrix to matrix multiplication is ***not commutative*** meaning that multiplication order matters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTtEzh_Xo9-c"
      },
      "source": [
        "## Identity Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoYfG5PVo9-c"
      },
      "source": [
        "***Identity Matrix***: an identity matrix is a square matrix with ones on the diagonal from the upper left to the bottom right and zeros everywhere else. We denote the identity matrix as $I_{n}$. We define $I∈R^{n×n}$ as: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKpDFSr__MRX"
      },
      "source": [
        "![Capture17](https://drive.google.com/uc?id=1-9KMKRdkZQLYs5IwnH0EoVG5ZY27MSST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zMyqBGdo9-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19efffa7-3b91-4d5c-ec07-654dcb23af5f"
      },
      "source": [
        "# 2x2 identity matrix\n",
        "I_2x2 = np.identity(2)\n",
        "print (I_2x2)\n",
        "print ('------------')\n",
        "\n",
        "# 3x3 identity matrix\n",
        "I_3x3 = np.identity(3)\n",
        "print (I_3x3)\n",
        "print ('------------')\n",
        "\n",
        "# 4x4 identity matrix\n",
        "I_4x4 = np.identity(4)\n",
        "print (I_4x4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]]\n",
            "------------\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "------------\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8370dYGo9-d"
      },
      "source": [
        "## Inverse Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLpVEoXo9-d"
      },
      "source": [
        "*** Inverse Matrix ***: matrix that when multiplied with another matrix (from either the right or the left side) returns the identity matrix.  Matrices that don't have an inverse are called noninvertible or singular matrices. <br>\n",
        "\n",
        "Since matrices cannot be divided, inversion can be used instead since multiplying by 1/3 is the same as dividing by 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPoFYgvRo9-d"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqDPuez_Hgd3"
      },
      "source": [
        "![Capture18](https://drive.google.com/uc?id=1yE9YYlfYgttM7WhEI72YHuEAIijXwrY8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6PRa62o9-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2bff02-33b4-449e-f3d1-2cebf08bcb96"
      },
      "source": [
        "# 2x2 matrix example \n",
        "z = np.array([[4, 3],\n",
        "              [3, 2]])\n",
        "\n",
        "print (z)\n",
        "print ('----------')\n",
        "\n",
        "# calculate inverse matrix\n",
        "z_inv = np.linalg.inv(z)\n",
        "print(z_inv)\n",
        "\n",
        "# check if inverse matrix is correct\n",
        "I = np.round(z_inv @ z) # matrix multiplication order mattered and using np.round() instead of np.dot() mattered\n",
        "print ('----------')\n",
        "print (I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 3]\n",
            " [3 2]]\n",
            "----------\n",
            "[[-2.  3.]\n",
            " [ 3. -4.]]\n",
            "----------\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7azi02ko9-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2ce129-f237-4105-ea91-55b4d4b025ca"
      },
      "source": [
        "# 3x3 matrix example \n",
        "z = np.array([[1, 4, 8],\n",
        "              [2, 1, 5],\n",
        "              [1, 7, 6]])\n",
        "\n",
        "print (z)\n",
        "print ('----------')\n",
        "\n",
        "# calculate inverse matrix\n",
        "z_inv = np.linalg.inv(z)\n",
        "print(z_inv)\n",
        "\n",
        "# check if inverse matrix is correct\n",
        "I = np.round(z_inv @ z, 2) # matrix multiplication order mattered and using np.round() instead of np.dot() mattered\n",
        "print ('----------')\n",
        "print (I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 4 8]\n",
            " [2 1 5]\n",
            " [1 7 6]]\n",
            "----------\n",
            "[[-0.61702128  0.68085106  0.25531915]\n",
            " [-0.14893617 -0.04255319  0.23404255]\n",
            " [ 0.27659574 -0.06382979 -0.14893617]]\n",
            "----------\n",
            "[[ 1.  0.  0.]\n",
            " [ 0.  1. -0.]\n",
            " [ 0. -0.  1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbgJrjZEo9-d"
      },
      "source": [
        "## Transpose Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHmRYcENo9-d"
      },
      "source": [
        "*** Transpose Matrix ***: matrix that when multiplied with another matrix from either the right or left side returns the identity matrix.  <br>\n",
        "\n",
        "Consider a matrix $M∈R^{m×n}$. The transpose of M is denoted as $M^T∈R^{n×m}$.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaW0MofVH9jI"
      },
      "source": [
        "![Capture19](https://drive.google.com/uc?id=1cyMe3jxPBhX-URy2JnyxfJAPabA0VpL7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1P4gJv2o9-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1860b86-cff4-4afe-bb25-d581ba832200"
      },
      "source": [
        "A = np.array([[3, -4], \n",
        "              [2, 0],\n",
        "              [-1, 6],\n",
        "              [5, 1]])\n",
        "\n",
        "# Use T method to transpose matrix \n",
        "A.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  2, -1,  5],\n",
              "       [-4,  0,  6,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1svik_Qo9-e"
      },
      "source": [
        "### Hadamard Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOBXL-nYo9-e"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNJbC9gxII4l"
      },
      "source": [
        "![Capture25](https://drive.google.com/uc?id=17OlTexcSiJWJa3F1FUATeMvjiXgDTEdL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geyfhlVao9-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33812a7-0e8f-4ba5-a9f2-5fd2add2aace"
      },
      "source": [
        "A = np.array([[3,5,7], [4, 9, 8]])\n",
        "B = np.array([[1, 6, 3], [0, 2, 9]])\n",
        "\n",
        "# Use multiply() or * to do hadamard product \n",
        "A*B         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3, 30, 21],\n",
              "       [ 0, 18, 72]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih0hRogyo9-e"
      },
      "source": [
        "## Special Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhDG09iyIYWk"
      },
      "source": [
        "![Capture91](https://drive.google.com/uc?id=1bwi9oZWPNLnjW5CihqLO8OWWGbpD4Qet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMtMpFoco9-f"
      },
      "source": [
        "### Echelon Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVbHD7LQo9-f"
      },
      "source": [
        "A matrix is said to be in echelon form when it has undergone the process of Gaussian Elimination. Specifically:\n",
        "1. zero rows are at the bottom of the matrix\n",
        "2. the leading entry (pivot) of each nonzero row is to the right of the leading entry of the row above it\n",
        "3. each leading entry is the only nonzero entry in its column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdBkKB-TIj86"
      },
      "source": [
        "![Capture25](https://drive.google.com/uc?id=1mK2yqmQaZS_Adn_iXcRcwzc4iy-wlxLB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OAFQ-NIo9-f"
      },
      "source": [
        "### Design Matrix ### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CIOmU-6o9-f"
      },
      "source": [
        "***Design matrix:*** special name for matrices containing explanatory variables or features in the context of statistics and machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoLY4_Fho9-f"
      },
      "source": [
        "# Systems of Linear Equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8oE3ElSo9-f"
      },
      "source": [
        "The purpose of linear algebra is to solve systems of linear equations. Informally, this means to figure out the right combination of linear segments to obtain a desired outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mY9cCaao9-g"
      },
      "source": [
        "#### Planes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL7hNhnSo9-g"
      },
      "source": [
        "Matrices are used to denote systems of linear equations.  Given matrix <i>A</i> and vectors v and y in $∈R^3$.  Setup the system of linear equations as Av = y:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq5Hj8gCIsAW"
      },
      "source": [
        "![Capture28](https://drive.google.com/uc?id=1rZOtDUz_mJy7Y0CzAiD9qVGwJJvsxdFR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMw7tmWo9-g"
      },
      "source": [
        "Geometrically the solution is equal to the line segment where the three planes intersect below: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMmnx2x8I6D9"
      },
      "source": [
        "![Capture29](https://drive.google.com/uc?id=1J4PQM9tbAXbI4fzRkmRvarLVphctI6dz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFjyOmsgo9-g"
      },
      "source": [
        "#### Linear Combination "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl7cU7Ulo9-g"
      },
      "source": [
        "Represent the system as a linear combination of the column vectors times a scaling term:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub1XVgwSJHZ-"
      },
      "source": [
        "![Capture31](https://drive.google.com/uc?id=1xzQNxNJPlLxLYrGZUXqRADviHbVs7jcL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVsu6vvuo9-h"
      },
      "source": [
        "### Solving Systems of Linear Equations w/Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw91iQrLo9-h"
      },
      "source": [
        "*** Gaussian Elimination: *** robust algorithm to solve linear systems by eliminating terms from a system of equations, such that it is simplified to the point where we obtain the row echelon form of the matrix.  Sequential application of three elementary transformations is needed:\n",
        "\n",
        "1. addition and subtraction of two equations (rows)\n",
        "2. multiplication of an equation (rows) by a number\n",
        "3. switching equations (rows)\n",
        "\n",
        "A consistent system of linear equations has at least one solution versus inconsistent systems that have no solution.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6WwIFapJY9w"
      },
      "source": [
        "![Capture34](https://drive.google.com/uc?id=1cYpI2xf_mRVEv2Q_0AVyxfu9gagLcpZS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G5FKFZEo9-h"
      },
      "source": [
        "*** Gauss-Jordan Elimination: *** only difference between Gaussian Elimination and Gauss-Jordan Elimination is that this time we “keep going” with the elemental row operations until we obtain the reduced row echelon form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKh-eNhOo9-h"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERoWPRBAJnBe"
      },
      "source": [
        "![Capture35](https://drive.google.com/uc?id=14xSXfiw0_QzsxBjBHWeV2sG4S-SRpxAN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsiQtR1_o9-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947cfe9e-78c6-4602-e3c6-084e9a284c53"
      },
      "source": [
        "A = np.array([[1,2,2], [1,3,3], [2,6,5]])\n",
        "y = np.array([4, 5, 6])\n",
        "\n",
        "# np.linalg.solve() solves Ax=y equations\n",
        "\n",
        "np.linalg.solve(A, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2., -3.,  4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuA5yP3go9-h"
      },
      "source": [
        "# Four Fundamental Matrix Subspaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c4bxD45o9-i"
      },
      "source": [
        "What are all possible subspaces that can be “covered” by a collection of vectors in a matrix?  There are four fundamental subspaces that can be “covered” by a matrix of valid vectors: \n",
        "1. the column space\n",
        "2. the row space\n",
        "3. the null space \n",
        "4. the left null space or null space of the transpose <br>\n",
        "\n",
        "These subspaces are considered fundamental because they express many important properties of matrices in linear algebra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6soTzBJo9-i"
      },
      "source": [
        "***Column Space C(A)***: composed of all linear combinations of the columns of matrix A.  So C(A)  is equal to the span of the columns of A.  For a matrix $A∈R^{m×n}$ and a vector $v∈R^m$, the column space is defined as: \n",
        "\n",
        "<center> $C(A) = {$w∈R^n$ | w=Av for some $v∈R^m$}$ </center> \n",
        "\n",
        "Formula in words: all linear combinations of the column vectors of A and entries of a n dimensional vector v "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnrF4TdJyzd"
      },
      "source": [
        "![Capture32](https://drive.google.com/uc?id=1-y49iqykg99DjJG4bwb9u3maodHau_2D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Ubum0Bo9-i"
      },
      "source": [
        "***Row Space R(A)***: composed of all linear combinations of the rows of matrix A.  In other words, R(A) is equal to the span of the rows of A.  A different way to see the row space, is by transposing $A^T$.  Now, we can define the row space simply as $R(A^T)$.  \n",
        "\n",
        "For a matrix $A∈R^{m×n}$ and a vector $v∈R^m$, the column space is defined as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFfYkbXxo9-i"
      },
      "source": [
        "<center> R(A) = {v ∈ ${R^m}$ | v = A${w^T}$ for some w ∈${R^n}$} </center> <br>\n",
        "\n",
        "Formula in words: all linear combinations of the row vectors of A and entries of a m dimensional vector w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpiajI5uJ7it"
      },
      "source": [
        "![Capture33](https://drive.google.com/uc?id=1I8Wb-2iOk3pXcNdRICDLz8BWVoBcTrvN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYBiQptno9-i"
      },
      "source": [
        "***Null Space N(A)***: null space of a matrix A is composed of all vectors that map into the zero vector when multiplied by A.  For a matrix $A∈R^{m×n}$ and a vector $v∈R^m$, the column space is defined as: <br>\n",
        "<center> N(A) = {v ∈ ${R^m}$ | Av = 0} </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3M7Yx0so9-i"
      },
      "source": [
        "***Null Space of the Transpose $N(A^T)$***: left null space of a matrix A is composed of all vectors that map into the zero vector when multiplied by A from the left. “From the left” means the vectors are on the left side of matrix A.  \n",
        "\n",
        "For a matrix $A∈R^{m×n}$ and a vector $v∈R^m$, the column space is defined as: <br>\n",
        "<center> N($A^T$) = {$w∈R^n$ | $v^TA$ = $0^T$} </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xalo_NRlo9-j"
      },
      "source": [
        "# Matrix Basis & Rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVP-Krxgo9-j"
      },
      "source": [
        "## Matrix Basis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV7h59vEo9-j"
      },
      "source": [
        "***Matrix Basis:*** a set of <i>n</i> linearly independent column vectors with <i>n</i> elements forms a basis. To find the basis of a matrix, find out which vectors are linearly independent of each other (i.e. pivots of the echelon form indicate the set of linearly independent vectors in a matrix)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MRHHzWPo9-j"
      },
      "source": [
        "NumPy does not have a method to obtain the row echelon form of a matrix.  SymPy does using rref() method.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzdRb7lCo9-j",
        "outputId": "91ec67f7-5cfe-4ca3-ea44-fe744f8c86eb"
      },
      "source": [
        "A = Matrix([[1, 2, 3, -1],\n",
        "            [2, -1, -4, 8],\n",
        "            [-1, 1, 3, -5],\n",
        "            [-1, 2, 5, -6],\n",
        "            [-1, -2, -3, 1]])\n",
        "\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[ 1,  2,  3, -1],\n",
              "[ 2, -1, -4,  8],\n",
              "[-1,  1,  3, -5],\n",
              "[-1,  2,  5, -6],\n",
              "[-1, -2, -3,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21nXogwjo9-k",
        "outputId": "0ae9519a-50d4-48d9-d9ad-9bd30c4d3642"
      },
      "source": [
        "A_rref, A_pivots = A.rref()\n",
        "\n",
        "A_rref"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[1, 0, -1, 0],\n",
              "[0, 1,  2, 0],\n",
              "[0, 0,  0, 1],\n",
              "[0, 0,  0, 0],\n",
              "[0, 0,  0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfCAn0DIo9-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c96021e-c584-4af7-8215-9991cb087e8f"
      },
      "source": [
        "print(f'pivot columns indexes are: {A_pivots}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pivot columns indexes are: (0, 1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPcXB4ko9-k"
      },
      "source": [
        "## Standard Basis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7G260r_o9-l"
      },
      "source": [
        "*** Standard Basis ***: a special orthonormal vector basis in which each basis vector has a single nonzero entry with value 1. <br>\n",
        "\n",
        "In $R^2$ space, the standard basis is: \n",
        "1. $e_1$ = $e_x$ = [1, 0]\n",
        "2. $e_2$ = $e_y$ = [0, 1]\n",
        "\n",
        "In $R^3$ space, the standard basis is: \n",
        "1. $e_1$ = $e_x$ = [1, 0, 0]\n",
        "2. $e_2$ = $e_y$ = [0, 1, 0]\n",
        "3. $e_3$ = $e_z$ = [0, 0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjibSx0Bo9-l"
      },
      "source": [
        "## Matrix Rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7PeIKIYo9-l"
      },
      "source": [
        "***Matrix Rank:*** maximal number of linearly independent columns of a matrix; from an applied machine learning perspective, the rank of a matrix is relevant as a measure of the information content of the matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PDa3oWEo9-l"
      },
      "source": [
        "<ul>\n",
        "<li>for a square matrix $R^{m×n}$ (where m=n), full rank when every column and/or row is linearly independent </li> \n",
        "<li>for a non-square matrix with $m > n$ (more rows than columns), full rank when every row is linearly independent </li> <li>when $m < n$ (more columns than rows), full rank when every column is linearly independent </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5ETur6KE7R"
      },
      "source": [
        "![Capture36](https://drive.google.com/uc?id=1F8jvLPkEyqwLvCDIM0uXTKnIxXfTWKIC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVHegxDno9-l"
      },
      "source": [
        "# Matrix Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jETASUlmo9-l"
      },
      "source": [
        "***Matrix Norm:*** measure the size of a matrix by computing its norm.  Three of the most commonly used norms in machine learning are:\n",
        "1. frobenius norm\n",
        "2. max norm\n",
        "3. spectral norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX37zyido9-l"
      },
      "source": [
        "***Frobenius Norm:*** think about this norm as flattening out the matrix into a long vector. For instance, a 3×3 matrix would become a vector with n=9 entries. <br>\n",
        "\n",
        "Formula in words: square each entry of matrix A, add them together, and then take the square root."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBi9uNzTKMb0"
      },
      "source": [
        "![Capture37](https://drive.google.com/uc?id=1jayMZbTk_hlmcVi4MrafQuRd0fgTYD7R)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfLAVgVKo9-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e32d56c-9771-4160-e5e6-f8e45caecccf"
      },
      "source": [
        "A = np.array([[-4, 2, 0],\n",
        "              [4, 1, 7], \n",
        "              [-1/2, 4, 10]])\n",
        "\n",
        "np.round(np.linalg.norm(A, 'fro'), 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV2jHSKIo9-m"
      },
      "source": [
        "***Max Norm / Infinity Norm:*** equals largest sum of the absolute value of maximal row vector\n",
        "\n",
        "Formula in words: equals going row by row, adding the absolute value of each entry, and then selecting the largest sum by row.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xneVqdreKTmM"
      },
      "source": [
        "![Capture38](https://drive.google.com/uc?id=1cer_jcv_bpzQlQvDVlG22oyRiwaRuZrx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1-uaupbo9-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e03ad0-fbf4-4c90-f5a5-b11398e7a42d"
      },
      "source": [
        "A = np.array([[-4, 2, 0],\n",
        "              [4, 1, 7], \n",
        "              [-1/2, 4, 10]])\n",
        "\n",
        "np.linalg.norm(A, np.inf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIw6Fy3Lo9-m"
      },
      "source": [
        "***Spectral Norm:*** equals to the largest singular value $σ_1$; related to eigenvectors and eigenvalues <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYJmjdzKKcu2"
      },
      "source": [
        "![Capture39](https://drive.google.com/uc?id=1WLIPsJiiliULjqcsXnm3LBzdsjvAT3nL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WJ2lu_Ao9-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0510462c-8e65-465e-eacd-abb1aec25df7"
      },
      "source": [
        "A = np.array([[-4, 2, 0],\n",
        "              [4, 1, 7], \n",
        "              [-1/2, 4, 10]])\n",
        "\n",
        "np.round(np.linalg.norm(A, 2), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Nu118wo9-n"
      },
      "source": [
        "# Linear & Affine Mappings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shA98SAXo9-n"
      },
      "source": [
        "## Linear Mappings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zqz6lYXo9-o"
      },
      "source": [
        "***Linear Mappings / Linear Transformations / Linear Functions:*** indicates the correspondence between vectors in a vector space V and the same vectors in a different vector space W <br>\n",
        "\n",
        "Linear mappings transform vector spaces into other vector spaces. Such transformations must be linear. Consider a linear mapping T and a pair of vectors x and y. To be valid, a linear mapping must satisfy these rules: \n",
        "1. T(x+y) = T(x)+T(y) \n",
        "2. T(αx) = αT(x), ∀α\n",
        "\n",
        "In linear algebra, linear mappings are represented as matrices and performed by matrix multiplication. Take a vector x and a matrix A. We say that when A multiplies x, the matrix transforms the vector into another vector: ***T(x) = Ax***\n",
        "\n",
        "Typical notation for a linear mapping: ***T:V → W*** ... (for the vector spaces V and W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBxPEZG8o9-o"
      },
      "source": [
        "## Linear Mapping Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ3B-qIto9-o"
      },
      "source": [
        "Dot products are linear mappings.  Two simple cases:     \n",
        "    1. negation \n",
        "    2. reversal  \n",
        "\n",
        "Examples below test this for one vector, but mapping works on the entire vector space (i.e. the span) of a given dimensionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z552bQXHo9-o"
      },
      "source": [
        "### Negation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUFZb_wCo9-o"
      },
      "source": [
        "***Negation Matrix:*** returns the opposite sign of each element of a vector <br>\n",
        "\n",
        "First test linear mapping: T(x+y) = T(x)+T(y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kyqeh9Bfo9-o"
      },
      "source": [
        "x = np.array([[-1],\n",
        "              [0],\n",
        "              [1]])\n",
        "\n",
        "y = np.array([[-3],\n",
        "              [0],\n",
        "              [2]])\n",
        "\n",
        "# negation matrix\n",
        "T = np.array([[-1,0,0],\n",
        "              [0,-1,0],\n",
        "              [0,0,-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY41CKDso9-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c352480-8447-445a-9687-037f1aa6db3b"
      },
      "source": [
        "# @ is dot product \n",
        "\n",
        "T@(x+y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4],\n",
              "       [ 0],\n",
              "       [-3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evdx6m7Io9-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a519048-1cd7-4d2c-b8e9-0a48e4015ae8"
      },
      "source": [
        "T@x + T@y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4],\n",
              "       [ 0],\n",
              "       [-3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guXqQgGIo9-p"
      },
      "source": [
        "Second test T(αx) = αT(x), ∀α:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYj26maEo9-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94580a9c-fe45-4b4e-ad73-131054f9b57f"
      },
      "source": [
        "alpha = 10\n",
        "\n",
        "T@(alpha*x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10],\n",
              "       [  0],\n",
              "       [-10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xElXC5SNo9-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a916f67c-7554-48bd-dd6f-0440d2636750"
      },
      "source": [
        "alpha*(T@x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10],\n",
              "       [  0],\n",
              "       [-10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WaFX5-5o9-p"
      },
      "source": [
        "### Reversal Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjyZ19F3o9-p"
      },
      "source": [
        "***Reversal Matrix:*** reverses the order of the elements of a vector; the last become the first, the second to last becomes the second, and so on "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wo0PX4Zo9-p"
      },
      "source": [
        "First test T(x+y) = T(x)+T(y):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ecJPFvqso9-q"
      },
      "source": [
        "x = np.array([[-1],\n",
        "              [0],\n",
        "              [1]])\n",
        "\n",
        "y = np.array([[-3],\n",
        "              [0],\n",
        "              [2]])\n",
        "\n",
        "# reversal matrix \n",
        "T = np.array([[0,0,1],\n",
        "              [0,1,0],\n",
        "              [1,0,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4st76alo9-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41b5762-e792-4e26-dc34-11b939cdb5dd"
      },
      "source": [
        "T@x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1],\n",
              "       [ 0],\n",
              "       [-1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cre6_hI2o9-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d80e3d-d576-47d3-8ea2-a980e2594e13"
      },
      "source": [
        "T@y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2],\n",
              "       [ 0],\n",
              "       [-3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4BcO8VZo9-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75ae00e-6a8e-4577-aad0-91ab02a81b90"
      },
      "source": [
        "T@(x+y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3],\n",
              "       [ 0],\n",
              "       [-4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy0O91a4o9-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25df17bf-3b50-4693-f8b9-f05ad1e9d27c"
      },
      "source": [
        "T@x + T@y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3],\n",
              "       [ 0],\n",
              "       [-4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFCiQlDMo9-r"
      },
      "source": [
        "Second test T(αx) = αT(x), ∀α:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oivE01CCo9-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1933e248-0e60-46ed-9d60-eb1e8774323b"
      },
      "source": [
        "alpha = 10\n",
        "\n",
        "T@(alpha*x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10],\n",
              "       [  0],\n",
              "       [-10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikueZMk_o9-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff37af87-2816-46d1-f0c7-2561cd4053e8"
      },
      "source": [
        "alpha*(T@x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10],\n",
              "       [  0],\n",
              "       [-10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsJJQsGOo9-r"
      },
      "source": [
        "## Special Linear Mappings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4gNsQY-o9-r"
      },
      "source": [
        "There are several important linear mappings (or transformations) that can be expressed as matrix-vector multiplications of the form ***y=Ax***. Such mappings are common in image processing, computer vision, and other linear applications.\n",
        "\n",
        "Combinations of linear and nonlinear mappings are what complex models such as neural networks do to learn mappings from inputs to outputs.  Six important linear mappings:\n",
        "1. Scaling\n",
        "2. Reflection\n",
        "3. Shear\n",
        "4. Rotation\n",
        "5. Projections onto lines\n",
        "6. Projections onto general subspaces "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLYFBlr3o9-r"
      },
      "source": [
        "### 1. Scaling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQnHmgzZo9-s"
      },
      "source": [
        "***Scaling:*** mapping of the form ***y=Ax, with A=αI***\n",
        "<ul>\n",
        "    <li> shrinks x when α<1 </li>\n",
        "    <li> reverses the direction of the vector when α<0 </li>\n",
        "    <li> scaling changes the size but not the shape of objects </li> \n",
        "</ul>\n",
        "\n",
        "Using $s_1$ and $s_2$ as scaling factors, a ***scaling matrix*** in $R^2$ takes the form: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV3mnRGlKkwj"
      },
      "source": [
        "![Capture46](https://drive.google.com/uc?id=1ZFhLoMDZ99174-HItqxY6u0QfSEC-qOx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKlPJNPOo9-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a614cc-1ada-4df1-f028-2bc1cb6b40a8"
      },
      "source": [
        "# let matrix A be the scaling matrix \n",
        "A = np.array([[5,0], [0,5]])\n",
        "print (A)\n",
        "print ('---------')\n",
        "\n",
        "x = np.array([[0,2], [0, 4]])\n",
        "print (x)\n",
        "print ('---------')\n",
        "\n",
        "y = A @ x  \n",
        "print (y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5 0]\n",
            " [0 5]]\n",
            "---------\n",
            "[[0 2]\n",
            " [0 4]]\n",
            "---------\n",
            "[[ 0 10]\n",
            " [ 0 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXts4P-qo9-s"
      },
      "source": [
        "### 2. Reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zYNykfio9-t"
      },
      "source": [
        "***Reflection:*** mirror image of an object in Euclidean space; reflection of a vector x through a line that passes through the origin is:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQKUV8RvKxfR"
      },
      "source": [
        "![Capture47](https://drive.google.com/uc?id=1MVa2hwS4robH07h-cliSYnkXZtPRMLlg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eplS0Jx7o9-t"
      },
      "source": [
        "Special cases of reflection: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMGXeEERo9-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9313117-7199-4d00-e75f-4715f54caed1"
      },
      "source": [
        "# reflection along the horizontal axis, or around the line at 0 degrees from the origin\n",
        "A1 = np.array([[1.0, 0],\n",
        "               [0, -1.0]])\n",
        "\n",
        "# reflection along the vertical axis, or around the line at 90∘ from the origin\n",
        "A2 = np.array([[-1.0, 0],\n",
        "               [0, 1.0]])\n",
        "\n",
        "# reflection along the line where the horizontal axis equals the vertical axis, or around the line at 45 degrees from the origin\n",
        "A3 = np.array([[0, 1.0],\n",
        "               [1.0, 0]])\n",
        "\n",
        "# Reflection along the line where the horizontal axis equals the negative of the vertical axis, or around the line at −45 degrees from the origin\n",
        "A4 = np.array([[0, -1.0],\n",
        "               [-1.0, 0]])\n",
        "\n",
        "x = np.array([[0,2], [0, 4]])\n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [0 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RI3zMKvko9-u"
      },
      "source": [
        "y1 = A1 @ x\n",
        "y2 = A2 @ x\n",
        "y3 = A3 @ x\n",
        "y4 = A4 @ x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-OY_qDEo9-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc49532d-db26-4315-81d0-50b205af4dd9"
      },
      "source": [
        "y1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  2.],\n",
              "       [ 0., -4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzjSt9lBo9-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8644fd81-c7f9-400e-ecfb-4171dfb4d37b"
      },
      "source": [
        "y2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -2.],\n",
              "       [ 0.,  4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lryTM3sQo9-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002226d9-7779-4a07-f6dd-33cd33c96b90"
      },
      "source": [
        "y3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 4.],\n",
              "       [0., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_VkTeco9-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e21794-b67f-4cc4-f264-14b66f266dd0"
      },
      "source": [
        "y4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -4.],\n",
              "       [ 0., -2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTnxWlX2K53i"
      },
      "source": [
        "![Capture48](https://drive.google.com/uc?id=1sML6nwwjxQLelDWGRJqGokstoSQIS0vl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM7bve1xo9-v"
      },
      "source": [
        "### 3. Shear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVspP5iNo9-v"
      },
      "source": [
        "***Shear:*** displaces points of an object in a given direction (i.e. all points to the right) in a proportion equal to their perpendicular distance from an axis that remains fixed; a “proportion equal to their perpendicular distance” means that points further away from the reference axis displace more than points near to the axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pad0Wh1o9-v"
      },
      "source": [
        "Having m as shear factor, for an object in $R^2$, a horizontal shear matrix takes the form:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHypbCWELC1E"
      },
      "source": [
        "![Capture49](https://drive.google.com/uc?id=1usULxCJAwEFCElZFdde0oF-rl6Uy7M1R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PNO8Safo9-v"
      },
      "source": [
        "Having m as shear factor, for an object in $R^2$, a vertical shear matrix takes the form:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esHYyCutLLgh"
      },
      "source": [
        "![Capture50](https://drive.google.com/uc?id=1VQvNLhZn2kJAFG9gb7Jui73hHsnupnxn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOpI2O6To9-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e520f6-a853-4a7b-b8e9-17a324bc1839"
      },
      "source": [
        "# shear along the horiontal axis\n",
        "A = np.array([[1.0, 1.5],\n",
        "               [0, 1.0]])\n",
        "print (A)\n",
        "print ('-------------')\n",
        "\n",
        "\n",
        "v = np.array([[2, 4,],\n",
        "              [0, 4]])\n",
        "print (v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  1.5]\n",
            " [0.  1. ]]\n",
            "-------------\n",
            "[[2 4]\n",
            " [0 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WWW0UxJUo9-v"
      },
      "source": [
        "y = A @ v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMjrFrCIo9-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d46c82e-5a11-408c-d960-74ecdcb07479"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2., 10.],\n",
              "       [ 0.,  4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhsxLrt3LU8g"
      },
      "source": [
        "![Capture51](https://drive.google.com/uc?id=1BZUIa48yxevE37UitryVsOjsBF-4DZEV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljiy49Pro9-w"
      },
      "source": [
        "### 4. Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBY1oypoo9-w"
      },
      "source": [
        "***Rotation:*** move objects counterclockwise in Euclidean space <br> \n",
        "\n",
        "For the general case in $R^2$, counterclockwise of vector x by θ radian rotations is obtained as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRS21xK2LbZS"
      },
      "source": [
        "![Capture52](https://drive.google.com/uc?id=1VJp3mQwFQzXYRqMb2QvCanmqLownlSLT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rgq-lo3o9-w"
      },
      "source": [
        "Special cases of rotation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ahzgPe-Ro9-w"
      },
      "source": [
        "# 90-degrees roration \n",
        "A1 = np.array([[0, -1.0],\n",
        "               [1, 0]])\n",
        "\n",
        "# 180-degrees roration \n",
        "A2 = np.array([[-1.0, 0],\n",
        "               [0, -1.0]])\n",
        "\n",
        "# 270-degrees roration \n",
        "A3 = np.array([[0, 1.0],\n",
        "               [-1.0, 0]])\n",
        "\n",
        "x = np.array([[0, 2.0,],\n",
        "              [0, 4.0,]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "p94dk17mo9-x"
      },
      "source": [
        "y1 = A1 @ x\n",
        "y2 = A2 @ x\n",
        "y3 = A3 @ x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdGraTlwo9-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce6924b-a2d7-4d4e-e739-1ec9f7b7d1a3"
      },
      "source": [
        "y1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -4.],\n",
              "       [ 0.,  2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOC0pkn1o9-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64aeb17-ff74-4c07-f02e-8098de1e9931"
      },
      "source": [
        "y2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -2.],\n",
              "       [ 0., -4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsYaDUL5o9-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7320df89-6dcb-49fe-f7ca-61f09ba73de5"
      },
      "source": [
        "y3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  4.],\n",
              "       [ 0., -2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sLzkr5Ljnj"
      },
      "source": [
        "![Capture53](https://drive.google.com/uc?id=1sETT_ydEzwvi55ykNlvx4E-fPlyyYNac)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uoynk5po9-x"
      },
      "source": [
        "# Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaFhTY-fo9-x"
      },
      "source": [
        "***Projections***: mappings from a space onto a subpace or from a set of vectors onto a subset of vectors; "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-AUSgC_o9-x"
      },
      "source": [
        "For a vector space V and a vector subset U ⊂ V, we define a projection ϕ as: <br>\n",
        "<center> ϕ : V→U with   ... $ϕ^2:ϕ∘ϕ=ϕ$ </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v6xCvyco9-y"
      },
      "source": [
        "### 5. Projections Onto Lines "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b90dUUg0LrG0"
      },
      "source": [
        "![Capture54](https://drive.google.com/uc?id=1SFgYus-1-UNtvYq4o1MbN0mz1QgiAfCV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d460lRzBo9-y"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0gqT9b9o9-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcd8477-8a92-4418-f041-dda86636c3b9"
      },
      "source": [
        "# find the projection Pϕ from vector b onto a basis vector a\n",
        "\n",
        "# base vector\n",
        "a = np.array([[5],\n",
        "              [1]])\n",
        "\n",
        "b = np.array([[1],\n",
        "              [4]])\n",
        "\n",
        "# projection matrix\n",
        "P = (a @ a.T) / (a.T @ a)\n",
        "P"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96153846, 0.19230769],\n",
              "       [0.19230769, 0.03846154]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVzT_1eVo9-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53eecc0d-f573-4d4e-ab55-efc76bbf68b7"
      },
      "source": [
        "# apply projection matrix to vector x\n",
        "b_pred = b.T @ P\n",
        "\n",
        "b_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.73076923, 0.34615385]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyfO8nQyL1UR"
      },
      "source": [
        "![Capture56](https://drive.google.com/uc?id=15r8L0jQfqNeC-I0ZiFYePdlHUoJArrOO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK7F35YYo9-y"
      },
      "source": [
        "### 6. Projections onto general subspaces "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EFc0iiFo9-y"
      },
      "source": [
        "*** General Subspace Projections:*** a group of people projecting themselves onto someone else, with that person representing a rough approximation of the character of the group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZfedl5Bo9-z"
      },
      "source": [
        "For set of basis vectors $a_1$ ... $a_m$, where A is the matrix of basis vectors: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijda9V_NL_Ah"
      },
      "source": [
        "![Capture57](https://drive.google.com/uc?id=1hhPtAc59qjeAYs1EGzqM_ghqVY4xyeSp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-v5t9go9-z"
      },
      "source": [
        "Formula in words: take the sum of the product between each basis vector and α; we want the projection to be the minimal distance from vector b onto A, which we know implies orthogonal lines connecting vector b with matrix A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwfkUM8to9-z"
      },
      "source": [
        "We know the values inside matrix A and vector b already so what we want to solve for is ***α*** (expression known as Moore–Penrose inverse of A): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDJyFyH0MHTq"
      },
      "source": [
        "![Capture58](https://drive.google.com/uc?id=1qbsPxT52CibOZgwfaHUSmvDD57prdtQI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wna0oKVgo9-z"
      },
      "source": [
        "Can be used to solve linear regression problems, although common notation is: $α = (X^TX)^{−1} X^Ty$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Ol4Ggyo9-z"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJVG6vfMPK1"
      },
      "source": [
        "![Capture59](https://drive.google.com/uc?id=1ZtdvACEiBtZyBemy4N_PAtzkLPvBtYK3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8go1b-S2o9-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83a10f6-9a25-4bb5-ede6-9e1448578f9d"
      },
      "source": [
        "# vector b\n",
        "b = np.array([3,-1,5])\n",
        "\n",
        "# matrix A\n",
        "A = np.array([\n",
        "    [1,2],\n",
        "    [-1,4],\n",
        "    [1,2]])\n",
        "\n",
        "# np.linalg.solve() solves Ax=b equations\n",
        "alpha = np.linalg.solve(A.T @ A, A.T @ b)\n",
        "print (alpha)\n",
        "print ('-------------')\n",
        "\n",
        "Ax = A @ alpha\n",
        "print(Ax.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.  0.5]\n",
            "-------------\n",
            "[ 4. -1.  4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKo0PJtVo9-0"
      },
      "source": [
        "### Projections Approximating Linear Equation Solutions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pINFu1Lo9-0"
      },
      "source": [
        "Machine learning prediction problems usually require analysts to find a solution to systems of linear equations of the form: ***y = Ax***.  In other words, to represent y as linear combinations of the columns of matrix A. <br>\n",
        "\n",
        "In most cases y is not in the column space of A meaning there is no way to find a linear combination of its columns to obtain the target y column.  In such cases, we can use orthogonal projections to find approximate solutions to the system. We usually denote approximated solutions for systems of linear equations as y^hat. <br>\n",
        "\n",
        "Now, y^hat will be in the span of the columns of A (meaning there exists a linear combination of A columns to obtain predicted y^hat column) and will be the result of projecting y onto the subspace of the columns of A. This solution will be the closest approximation of y given the span of the columns of A.\n",
        "\n",
        "***Summary:*** The approximated solution y^hat is the orthogonal projection of y onto matrix A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiHnbiU1o9-0"
      },
      "source": [
        "# Nonlinear Mapping Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3n_LGuSo9-1"
      },
      "source": [
        "***Norms:*** all norms are not linear transformations; See \"Matrix Norm\" section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDKpBNQpo9-1"
      },
      "source": [
        "## Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_uWYVEpo9-1"
      },
      "source": [
        "***Translation***: geometric transformation that moves every vector in a vector space by the same distance in a given direction (i.e. move a cup of coffee from your left to your right, and you would have performed translation in $R^3$ space).\n",
        "\n",
        "The translation matrix is represented with ***homogeneous coordinates*** instead of cartesian coordinates. The homogeneous coordinate system adds an extra 1 at the end of vectros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4JNCW-6o9-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d86227-0823-4a8d-cc80-f9d59209b5c7"
      },
      "source": [
        "# vector in R^2 cartesian coordinates\n",
        "\n",
        "x=np.array([[3], [3]])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_DF8lzOo9-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dded64c3-b966-4e3a-b2a9-28eb08d8a6cd"
      },
      "source": [
        "# becomes the following in R^2 homogeneous coordinates\n",
        "\n",
        "x=np.array([[3], [3], [1]])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [3],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3AycfPWo9-1"
      },
      "source": [
        "The translation matrix for the general case cannot be represented with Cartesian coordinates. Homogeneous coordinates are the standard in fields like computer graphics since they allow us to better represent a series of transformations (or mappings) like scaling, translation, rotation, etc. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Hye4-9o9-1"
      },
      "source": [
        "Step by Step Math Problem Example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuYyrbK7MXkk"
      },
      "source": [
        "![Capture40](https://drive.google.com/uc?id=1CvKCNo4IzN5n63DSAGD2XtDYzuinxekz)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rYeVvQ-o9-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf4eb57-3fa7-4714-99bb-fcd20f600eec"
      },
      "source": [
        "# translation matrix\n",
        "T = np.array([ [1, 0, 3],\n",
        "               [0, 1, 1], \n",
        "               [0, 0, 1]])\n",
        "\n",
        "print (T)\n",
        "print ('----------')\n",
        "\n",
        "# vector x\n",
        "x = np.array([ [2, 2, 1] ])\n",
        "print (x.T)\n",
        "\n",
        "T @ x.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 3]\n",
            " [0 1 1]\n",
            " [0 0 1]]\n",
            "----------\n",
            "[[2]\n",
            " [2]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5],\n",
              "       [3],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXcHS2Qjo9-2"
      },
      "source": [
        "# Affine Mappings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg44yq2Co9-2"
      },
      "source": [
        "***Affine Mappings:*** linear mapping + translation; an affine mapping M takes the form below where variable A is a linear mapping or transformation and variable b is the translation vector: ***M(x) = Ax+b*** <br>\n",
        "\n",
        "Linear regression is usually analyzed as a linear mapping plus noise, but it can also be seen as an affine mapping.  Alternative, we can say that Ax+b is a linear mapping if and only if b=0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65IjjPFzMfLX"
      },
      "source": [
        "![Capture41](https://drive.google.com/uc?id=16A6eygG0OycakMnPiFiC6ztGE04C4Yvr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2tbnfRFo9-2"
      },
      "source": [
        "### Affine Combination of Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHOed_eAo9-2"
      },
      "source": [
        "***Affine Combinations of Vectors:*** are linear combinations with an added constraint in which the sum of weights β must equal 1.  Linear combination definition (vectors $x_1$…$x_k$ and scalars $β_1$…$β_k ∈ R$): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw749QSFMmQZ"
      },
      "source": [
        "![Capture42](https://drive.google.com/uc?id=1FdXAr0bPhUxCKvDRV12vGQTQdI_o1E_N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyvFczHwo9-2"
      },
      "source": [
        "In practice, this defines a weighted average of the vectors.  Chart below shows general consequence of constraining the sum of the weights to 1: every affine combination of the same set of vectors will map onto the same space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4enmCXJMtRN"
      },
      "source": [
        "![Capture43](https://drive.google.com/uc?id=1rZK5RCHKUPLH0MQAWCYt3FpYsnwlqqu5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrUmy78Ao9-3"
      },
      "source": [
        "### Affine Span"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP9qwzT4M0Tt"
      },
      "source": [
        "![Capture44](https://drive.google.com/uc?id=1_Bj1HtfehtnkhTI1g86zJcdymccdirvc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNhiT4xRo9-3"
      },
      "source": [
        "***Affine Span:*** set of all linear combinations of the vector set such that the weights add up to 1 and all weights are real numbers. Hence, the fundamental difference between vector spaces and affine spaces, is the former will span the entire $R^n$ space (assuming independent vectors), whereas the latter will span a line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjD6a3j2o9-3"
      },
      "source": [
        "Three cases in $R^3$:\n",
        "1. 3 linearly independent vectors: affine span is 2-D plane containing these vectors \n",
        "2. 2 linearly independent vectors: affine span is line\n",
        "3. 3 linearly dependent vectors: affine span is single point "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LmLp750o9-3"
      },
      "source": [
        "### Affine Space & Subspace "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEoaRGpfo9-3"
      },
      "source": [
        "***Affine Spaces:*** translations of vector spaces (vector spaces that have been offset from the origin of the coordinate system); any point, line, plane, or hyperplane in $R^n$ that does not go through the origin is an affine subspace (i.e. linear regression is an affine subspace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ofcqNBo9-4"
      },
      "source": [
        "### Affine Transformation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2xRQi9xo9-4"
      },
      "source": [
        "Consider the matrix $A∈R^{m×n}$ and vectors x, b, $y∈R^n$ <br>\n",
        "We can represent the system of linear equations ***Ax+b = y*** as a single matrix vector multiplication by using an augmented matrix known as affine transformation matrix: <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUy3COykM9Ns"
      },
      "source": [
        "![Capture45](https://drive.google.com/uc?id=1hBr0hTOLaOpYooy-t5auZ0ZiCBwppgkA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBMci-v5o9-4"
      },
      "source": [
        "# Matrix Decompositions / Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocCtSVpWo9-4"
      },
      "source": [
        "***Matrix Decomposition:*** break down a matrix into simpler elements / matrices to better understand its fundamental structure; opposite of linear combinations;  multiple ways to decompose matrices  <br>\n",
        "\n",
        "Applications of matrix factorization in machine learning include: clustering, recommender systems, dimensionality reduction, topic modeling, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i75XS_SHo9-5"
      },
      "source": [
        "## Lower-Upper (LU) Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zN2l_po9-5"
      },
      "source": [
        "***LU Decomposition:*** decompose a matrix into a lower triangular matrix (L) and an upper triangular matrix (U); can represent Gaussian Elimination (GE) in linear algebra; can be obtained from noninvertible matrices (matrix with no inverse) and from non-square matrices; in LU decomposition, use elementary matrices to perform GE style row operations  <br>\n",
        "\n",
        "Formula (Matrix A represented as the product of lower triangular matrix L and upper triangular matrix U): \n",
        "<center> $A = LU$ </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40-6uzSQo9-5"
      },
      "source": [
        "### Elementary Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeEJx2M3o9-5"
      },
      "source": [
        "***Elementary Matrices:*** obtaining any lower triangular matrix via simple column or row operations (i.e. addition and multiplication); elementary matrices “encode” fundamental column and row operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug9lkBGNGCp"
      },
      "source": [
        "![Capture60](https://drive.google.com/uc?id=1x-Ck4dK2s3syqMGBqnGcaWsdpfQ5NXhX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9S1NpWCo9-5"
      },
      "source": [
        "Introduction to Elementary Matrices:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAvkD3WSNNOS"
      },
      "source": [
        "![Capture64](https://drive.google.com/uc?id=1HlBEf5iuYASg1HF5uVLBYGOidkxSzJPs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I17p7T6o9-6"
      },
      "source": [
        "### The Inverse of Elementary Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUl5Hi4o9-6"
      },
      "source": [
        "Inverse is simply the opposite operation (i.e. multiply first row by 5, now divide first row by 5):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLVT7QSoNXlb"
      },
      "source": [
        "![Capture61](https://drive.google.com/uc?id=1HOpyyteTnhtVMFf7ZAfAvu-wcT8b1t8-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxdy3nwVo9-6"
      },
      "source": [
        "### LU Decomposition as Gaussian Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba99mMJMo9-6"
      },
      "source": [
        "***Gaussian Elimination:*** robust algorithm to solve systems of linear equations (see earlier section); reduce matrices to row echelon form (upper triangular matrix) with zero rows at the bottom and zeros below the pivot for each column\n",
        "\n",
        "Elementary matrices can cleverly organize the steps from Gaussian Elimination because you can represent row operations as <i> multiplication by elementary matrices</i> instead.  See example below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD_TeRico9-6"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAVfr8l3NjGi"
      },
      "source": [
        "![Capture65](https://drive.google.com/uc?id=1DAQUpmW9vGahjpvDxt0kAxm4zzSW-aKm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz_-v2p1o9-7"
      },
      "source": [
        "Reduce Matrix A to row echelon form by creating lower triangular matrix using elementary matrices "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368WStYHo9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70031b58-b9d7-4b4e-f46f-0ea7f29f64c4"
      },
      "source": [
        "# notice how we are impacting the second row only \n",
        "# replicating R2-2R1\n",
        "\n",
        "A = np.array([[1, 3, 5],\n",
        "              [2, 2, -1],\n",
        "              [1, 3, 2]])\n",
        "\n",
        "l1 = np.array([[1, 0, 0],\n",
        "               [-2, 1, 0],\n",
        "               [0, 0, 1]])\n",
        "\n",
        "l1 @ A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   3,   5],\n",
              "       [  0,  -4, -11],\n",
              "       [  1,   3,   2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhzqxoTTo9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a061cf2-4ec9-4f2e-d1f8-0ef59c3fb2b7"
      },
      "source": [
        "# need to create all 0's in lower triangle: equivalent of R3-R1 \n",
        "l2 = np.array([[1, 0, 0],\n",
        "               [-2, 1, 0],\n",
        "               [-1, 0, 1]])\n",
        "\n",
        "# U = l2@A = upper triangular matrix resulting from Gaussian Elimination \n",
        "U = l2 @ A\n",
        "U"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   3,   5],\n",
              "       [  0,  -4, -11],\n",
              "       [  0,   0,  -3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU_sbXjio9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82134a6b-e6eb-4943-b6d0-116fe595317d"
      },
      "source": [
        "# A = LU so we need to find L\n",
        "# L is the inverse of l2\n",
        "\n",
        "L = np.linalg.inv(l2)\n",
        "L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1., -0., -0.],\n",
              "       [ 2.,  1.,  0.],\n",
              "       [ 1.,  0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpJpxM9Bo9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bf859d-6c67-4c33-fa2b-9d1abb3a8723"
      },
      "source": [
        "# check if A = LU\n",
        "\n",
        "L @ U"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  3.,  5.],\n",
              "       [ 2.,  2., -1.],\n",
              "       [ 1.,  3.,  2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ecPhTLo9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2291dd4b-88d8-4c08-d683-f67dbde57f38"
      },
      "source": [
        "# confirmed that we recover A by multiplying L*U\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  3,  5],\n",
              "       [ 2,  2, -1],\n",
              "       [ 1,  3,  2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjEr2sGxo9-8"
      },
      "source": [
        "### LU Decomposition w/Pivoting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YxLYux0o9-8"
      },
      "source": [
        "LU decomposition does not work when permutations of rows are required to solve a system of linear equations.  Therefore, to perform all possible Gaussian Eliminations, permutation matrices (P) will need to be utilized.  The complete decomposition of Matrix A is: <br>\n",
        "\n",
        "<center> $A = LUP$ </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQZxLFgbo9-8"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73NfwZLbNyM6"
      },
      "source": [
        "![Capture66](https://drive.google.com/uc?id=1b9Oe1a81grSc87Xl3T-tvvauNn9HVO9b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6EwXYGeo9-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9d5ce7-8fba-4e83-afe4-4d5993dff448"
      },
      "source": [
        "P = np.array([[0, 1],\n",
        "              [1, 0]])\n",
        "A = np.array([[0, 1],\n",
        "              [1, 1]])\n",
        "\n",
        "P @ A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ7aTe5xo9-9"
      },
      "source": [
        "Use SciPy to perform LUP decomposition by using the linalg.lu() method: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDdrZ-UOo9-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c6fdb0-33fc-420c-da0d-76eaac307f5b"
      },
      "source": [
        "A = np.array([[-1, 3, 1, 0],\n",
        "              [7, 1, 6, 1],\n",
        "              [2, 7, 4, -2],\n",
        "              [2, 3, -9, 4]])\n",
        "\n",
        "P, L, U = lu(A)\n",
        "\n",
        "print(f'pivot matrix P is:\\n{P}')\n",
        "print(f'----------------------------------')\n",
        "print(f'upper triangular matrix U is:\\n{np.round(U, 2)}')\n",
        "print(f'----------------------------------')\n",
        "print(f'lower triangular matrix L is:\\n{np.round(L, 2)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pivot matrix P is:\n",
            "[[0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]]\n",
            "----------------------------------\n",
            "upper triangular matrix U is:\n",
            "[[  7.     1.     6.     1.  ]\n",
            " [  0.     6.71   2.29  -2.29]\n",
            " [  0.     0.   -11.64   4.64]\n",
            " [  0.     0.     0.     1.53]]\n",
            "----------------------------------\n",
            "lower triangular matrix L is:\n",
            "[[ 1.    0.    0.    0.  ]\n",
            " [ 0.29  1.    0.    0.  ]\n",
            " [ 0.29  0.4   1.    0.  ]\n",
            " [-0.14  0.47 -0.07  1.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5a0fwlGo9-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778946c9-73ae-4284-e84f-98bdc1525b45"
      },
      "source": [
        "# confirm decomposition is right by multiplying L*U*P which should return matrix A\n",
        "\n",
        "P @ L @ U"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.,  3.,  1.,  0.],\n",
              "       [ 7.,  1.,  6.,  1.],\n",
              "       [ 2.,  7.,  4., -2.],\n",
              "       [ 2.,  3., -9.,  4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFH11flvo9-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5a49e6-0001-4b18-d487-29f883229f80"
      },
      "source": [
        "# original matrix A is recovered \n",
        "\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1,  3,  1,  0],\n",
              "       [ 7,  1,  6,  1],\n",
              "       [ 2,  7,  4, -2],\n",
              "       [ 2,  3, -9,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shsoH451o9-9"
      },
      "source": [
        "# QR Decomposition / QR Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWyptK1So9--"
      },
      "source": [
        "***QR Decomposition***: used to solve systems of linear equations like least square problems and to find eigenvalues of a general matrix; decomposes matrix A into an orthogonal matrix Q and a upper traingular matrix R: \n",
        "<center> $A = QR$ </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1l05ip_o9--"
      },
      "source": [
        "## Orthonormal Basis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhpl6gr2o9--"
      },
      "source": [
        "Orthogonal vectors form an orthogonal basis for matrix A and for the vector space spanned by such matrix.  Once you divide each vector in Matrix A by its length or norm, a unit basis vector is produced.  This produces an ***orthonormal basis***. <br>\n",
        "\n",
        "Normalized unit vector u (\"hat\" is added to vector u to signify normalized vector):  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzJkehZMN7kf"
      },
      "source": [
        "![Capture68](https://drive.google.com/uc?id=1EQ4Ykfz1mX00zMOaKuzYuo2HOQMJD7_5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzZDDPhko9--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77117d6-48df-4b9e-f219-e56bc4326a11"
      },
      "source": [
        "x = np.array([[3],[4],[0]])\n",
        "y = np.array([[-4],[3],[2]])\n",
        "\n",
        "print (x)\n",
        "print ('--------')\n",
        "print (y)\n",
        "print ('--------')\n",
        "\n",
        "# check if vectors are orthogonal --> yes\n",
        "x.T @ y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]\n",
            " [4]\n",
            " [0]]\n",
            "--------\n",
            "[[-4]\n",
            " [ 3]\n",
            " [ 2]]\n",
            "--------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voeM3hbNo9--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d63628-23ff-4cb9-a6ae-ded03463ab3a"
      },
      "source": [
        "# normalize unit vectors\n",
        "\n",
        "x_unit = x * (1/(np.linalg.norm(x, 2))) # denominator is Euclidean norm\n",
        "y_unit = y * (1/(np.linalg.norm(y, 2)))\n",
        "\n",
        "print (x_unit) # magnitude is one\n",
        "print ('------')\n",
        "print (np.round(y_unit, 2)) # magnitude is one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6]\n",
            " [0.8]\n",
            " [0. ]]\n",
            "------\n",
            "[[-0.74]\n",
            " [ 0.56]\n",
            " [ 0.37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jpFoDdlo9--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6e9e34-edc4-4d86-aca0-0f592e572450"
      },
      "source": [
        "# confirm magnitude of each vector equals 1 --> yes\n",
        "\n",
        "print (np.linalg.norm(x_unit, 2))\n",
        "print ('----')\n",
        "print (np.round(np.linalg.norm(y_unit, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "----\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjDo64q8o9--"
      },
      "source": [
        "### Orthonormal Basis Transpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unsy48Cvo9--"
      },
      "source": [
        "***Q***: special case of a matrix composed of ***orthonormal vectors***; the matrix product with its transpose equals the identity (<i>Q</i> does not need to be square): \n",
        "<br>\n",
        "\n",
        "<center> $Q^TQ=I$ </center> <br>\n",
        "Above property will be useful for several applications later in this notebook (i.e. coupling matrix, correlation matrix, fourier series, least square problems, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TlVJjrNo9-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6ff846-c04a-4b77-c5e6-9787e6752586"
      },
      "source": [
        "Q = np.column_stack((x_unit, y_unit))\n",
        "\n",
        "Q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6       , -0.74278135],\n",
              "       [ 0.8       ,  0.55708601],\n",
              "       [ 0.        ,  0.37139068]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKt2Rbyo9-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe64a34-1e88-4bf2-a27f-d11a67d36b07"
      },
      "source": [
        "np.round(Q.T @ Q,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1., -0.],\n",
              "       [-0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5wb-Iaio9-_"
      },
      "source": [
        "### Gram-Schmidt Orthogonalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0VfOfybo9-_"
      },
      "source": [
        "*** Gram-Schmidt Orthogonalization Procedure:*** transforms a set of non-orthogonal vectors into orthogonal vectors; take the vectors of a matrix, one by one, and make each subsequent vector <i> orthonormal </i> to the previous one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cegEK8ztOY3x"
      },
      "source": [
        "![Capture92](https://drive.google.com/uc?id=1GG2t7vJmKNPHcL2X7MH8mNMPJ0HaFrTA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7U-i6AIo9-_"
      },
      "source": [
        "Check if the columns of matrix A are orthonormal: compute $A^TA$.  If it is orthonormal, result = identity matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MeW-Uyyo9_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee45210d-a46c-48d8-ba2c-3166fd81677a"
      },
      "source": [
        "A = np.array([[2, 1, -2],\n",
        "              [7, -3, 1],\n",
        "              [-3, 5, -1]])\n",
        "\n",
        "# check if A is orthonormal --> No\n",
        "A.T @ A "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 62, -34,   6],\n",
              "       [-34,  35, -10],\n",
              "       [  6, -10,   6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiwkOZrYo9_A"
      },
      "source": [
        "Generate $q_2$ from $a_2$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k638O3Cbo9_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e03d2e4-ea96-4cda-cd05-854a79c01493"
      },
      "source": [
        "a1 = A[:, 0]\n",
        "q1 = A[:, 0]\n",
        "\n",
        "a2 = A[:, 1]\n",
        "q2 = a2 - ((q1.T @ a2)/(q1.T @ q1)) * q1 # formula \n",
        "\n",
        "q2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.09677419, 0.83870968, 3.35483871])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLQBQ4DRo9_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5057d626-e11c-4c26-8fb8-433ec6827bd9"
      },
      "source": [
        "# solved for q2 above; q2 should be orthogonal to q1 --> verify \n",
        "\n",
        "np.round(q2.T @ q1, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZDbmYvEo9_A"
      },
      "source": [
        "Generate $q_3$ from $a_3$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_3EME3Qo9_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae173280-cac1-4798-acb5-152d8cf937e5"
      },
      "source": [
        "a3 = A[:, 2]\n",
        "q3 = a3 - (((q1.T @ a3)/(q1.T @ q1)) * q1) - (((q2.T @ a3)/(q2.T @ q2)) * q2) # formula\n",
        "\n",
        "q3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.33333333,  0.66666667,  0.66666667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvYL30kFo9_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba30b0d-9fc9-400c-929c-d96fc128f038"
      },
      "source": [
        "# solved for q3 above; q3 should be orthogonal to q1 and q2 --> verify \n",
        "\n",
        "print (np.round(q1 @ q3))\n",
        "print ('-------')\n",
        "print (np.round(q1 @ q2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n",
            "-------\n",
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da9PWRmRo9_B"
      },
      "source": [
        "Generate matrix Q' by having $q_1$, $q_2$, and $q_3$ be the column spans of matrix.  Q' matrix has orthogonal, but not normal vectors.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl35GAZso9_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dabe4de-2bb3-4f82-dabb-2875e0d91e73"
      },
      "source": [
        "Q_prime = np.column_stack((q1, q2, q3))\n",
        "\n",
        "np.round(Q_prime)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.,  2., -1.],\n",
              "       [ 7.,  1.,  1.],\n",
              "       [-3.,  3.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyHu2sSzo9_B"
      },
      "source": [
        "Matrix Q needs to have orthonormal vectors: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hux4ZUCo9_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43aa4673-4683-4d68-c225-927eff76a497"
      },
      "source": [
        "Q_norms = np.linalg.norm(Q_prime, 2, axis=0)\n",
        "Q_norms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.87400787, 4.04411161, 1.63299316])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfgIdR9so9_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c6db3f-f011-43f7-ca52-6784a21deb85"
      },
      "source": [
        "# Q is solved \n",
        "\n",
        "Q = Q_prime / Q_norms\n",
        "np.round(Q, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.25,  0.52, -0.82],\n",
              "       [ 0.89,  0.21,  0.41],\n",
              "       [-0.38,  0.83,  0.41]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqFbExd7o9_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e7650c-98fb-4393-92fa-4292e2f8c48c"
      },
      "source": [
        "# verify each vector has magnitude of 1\n",
        "\n",
        "np.linalg.norm(Q , 2, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf7lAfsco9_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dc78e0-d468-4ad5-84a1-653f031587f0"
      },
      "source": [
        "# verify code is correct: compute Q^T * Q = I --> Yes\n",
        "\n",
        "np.round(Q.T @ Q, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1., -0., -0.],\n",
              "       [-0.,  1.,  0.],\n",
              "       [-0.,  0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YefCSZPJo9_C"
      },
      "source": [
        "### QR Decomposition as Gram-Schmidt Orthogonalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6HzI_7oo9_C"
      },
      "source": [
        "***Gram-Schmidt Orthogonalization can be represented as QR Decomposition***, similar to how Gaussian Elimination can be represented as LU decomposition.  In QR decomposition, elementary matrices are used to perform column operations.  Specifically, an upper triangular matrix is used to perform column operations in QR decomposition by multiplying A from the right side.\n",
        "\n",
        "Decompose Matrix A into matrices Q and R.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMuomkvso9_C"
      },
      "source": [
        "Shortcut using qr() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xV6gHfxHo9_C"
      },
      "source": [
        "A = np.array([[2, 1, -2],\n",
        "              [7, -3, 1],\n",
        "              [-3, 5, -1]])\n",
        "\n",
        "# we should get same matrix using Q_qr vs. Q but we don't because the signs are flipped\n",
        "# it's a stability and approximation issue to be aware of\n",
        "Q_qr, R = np.linalg.qr(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPqhWEaUo9_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3918a6ba-e67f-412a-c8fe-55f6891b13e7"
      },
      "source": [
        "Q_qr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.25400025,  0.51847585, -0.81649658],\n",
              "       [-0.88900089,  0.20739034,  0.40824829],\n",
              "       [ 0.38100038,  0.82956136,  0.40824829]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z-8u_KDo9_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc3edb6-f385-44c2-fada-80cd8d3aae7f"
      },
      "source": [
        "R"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-7.87400787,  4.31800432, -0.76200076],\n",
              "       [ 0.        ,  4.04411161, -1.65912271],\n",
              "       [ 0.        ,  0.        ,  1.63299316]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU3cVZ5zo9_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7762920a-ed3c-4453-d093-61e782f99501"
      },
      "source": [
        "# returns original A matrix \n",
        "\n",
        "(Q_qr) @ R"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.,  1., -2.],\n",
              "       [ 7., -3.,  1.],\n",
              "       [-3.,  5., -1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl3PaIZ4o9_D"
      },
      "source": [
        "# Determinant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukyOaAYbo9_F"
      },
      "source": [
        "***Matrix Determinant:*** scalar number providing critical information about the matrix.  Specifically: \n",
        "1. matrix is invertible / has inverse if determinant is not zero\n",
        "2. columns of matrix are linearly independent if determinant is not zero\n",
        "\n",
        "Determinants can also be used to find area of $R^2$ matrix (i.e. parallelogram) or volume of $R^3$ matrix.  This topic plays a critical conceptual role in matrix decomposition, particularly eigenvalues and eigenvectors later on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO3nffRlo9_F"
      },
      "source": [
        "## 2 X 2 Determinant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y2eiiqqOjDg"
      },
      "source": [
        "![Capture73](https://drive.google.com/uc?id=1vkD_uTrL41A3izfZXm_RILnDJpH1EPv4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JwIENZWo9_G"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UXZmlqsOqK4"
      },
      "source": [
        "![Capture75](https://drive.google.com/uc?id=1M5geGcAe3mv4Lqg7v6dotI95TxHMGD5y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-31T16:56:22.670365Z",
          "start_time": "2020-12-31T16:56:22.567617Z"
        },
        "id": "DZd5Fvc7o9_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bf8836-dbc4-4049-a915-1022f22171b3"
      },
      "source": [
        "# 2x2 matrix\n",
        "\n",
        "A = np.array([[1, 3], [2, -3]])\n",
        "\n",
        "A_det = np.round(np.linalg.det(A), 2)\n",
        "A_abs = np.abs(np.round(np.linalg.det(A), 2))\n",
        "\n",
        "print(f'determinant of matrix A equals: {A_det}')\n",
        "print(f'area of parallelogram with column span of matrix A as vectors: {A_abs} units^2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "determinant of matrix A equals: -9.0\n",
            "area of parallelogram with column span of matrix A as vectors: 9.0 units^2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Ox4Tfho9_H"
      },
      "source": [
        "## N X N Determinant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05UahErMOymi"
      },
      "source": [
        "![Capture74](https://drive.google.com/uc?id=1S7j88bjd8HelF4vWVhD6b5K8cNRmPheP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snylCqE9o9_H"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMOxVN5GO4RC"
      },
      "source": [
        "![Capture76](https://drive.google.com/uc?id=1K7YEYWhtsliDbUHyGa8N4RwPD1wZS9wr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7p76Z5po9_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36378ba-f137-4cf9-e0d3-843ad962769a"
      },
      "source": [
        "# 3x3 matrix \n",
        "\n",
        "A = np.array([[1, 3, 2], [-3, -1, -3], [2, 3, 1]])\n",
        "A_det=np.round(np.linalg.det(A), 2)\n",
        "A_abs = np.abs(np.round(np.linalg.det(A), 2))\n",
        "\n",
        "print(f'determinant of matrix A equals: {A_det}')\n",
        "print(f'volume of parallelepid with column span of matrix A as vectors: {A_abs} units^2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "determinant of matrix A equals: -15.0\n",
            "volume of parallelepid with column span of matrix A as vectors: 15.0 units^2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Zzjx7Jo9_H"
      },
      "source": [
        "## Determinants as Scaling Factors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGkuOCkoo9_I"
      },
      "source": [
        "***Determinants as Scaling Factors***: can be viewed as the factor by which areas are scaled under a linear mapping.  For example, if you do a mapping using a matrix and the area increases by a factor of 5, then the determinant of the transformation matrix equals 5.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq0Qaamdo9_I"
      },
      "source": [
        "Step by Step Math Problem Example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOPVICj5O_Qv"
      },
      "source": [
        "![Capture77](https://drive.google.com/uc?id=1TBNunwk1My5Pf1wrR_69Z9bB-EduG0s_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxA9Ztt_o9_I"
      },
      "source": [
        "Vertical axis scaled by 3 and horizontal axis scaled by 2 using matrix A: new area increased by factor of 6 which equals determinant of Matrix A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9BOff1No9_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d051ae79-ee6f-4132-e9eb-400b72046cea"
      },
      "source": [
        "A = np.array([[3, 0],\n",
        "              [0, 2]])\n",
        "\n",
        "x = np.array([2,2])\n",
        "\n",
        "A @ x.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA9aheXJo9_I"
      },
      "source": [
        "# Eigen Related Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi-dR4p5o9_I"
      },
      "source": [
        "***Eigen Related Concepts*** are used in machine learning programs such as markov chains, PCA, clustering, recommendation systems, etc.  Some concepts being covered: \n",
        "1. change of basis\n",
        "2. eigenvalues, eigenvectors, eigenspaces \n",
        "3. trace and determinant with eigenvalues\n",
        "4. eigendecomposition\n",
        "5. geometric interpretation of eigendecomposition\n",
        "6. eigenbasis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyaqKNITo9_J"
      },
      "source": [
        "## Change of Basis for Vectors "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8NjM3l5o9_J"
      },
      "source": [
        "For a given vector space, <i>n</i> linearly independent vector(s) with <i>n</i> elements forms its basis.  One set of basis vector(s) can be \"moved\" or transformed to another set of basis vector(s) with linear mappings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zHhaAFo9_J"
      },
      "source": [
        "### Standard Basis Vector as Linear Combo of Another Basis Vector Set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxs8UGwro9_J"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDvNhhVWPGqz"
      },
      "source": [
        "![Capture80](https://drive.google.com/uc?id=1eu-9FiFPBLvPrfb8rNKfYy6ysL_paw2D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxVafR6jo9_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57d39d4-2030-4c69-d3dc-a6ee538623a5"
      },
      "source": [
        "# Ax=u\n",
        "# x: new vector basis\n",
        "# x=A^-1*u\n",
        "\n",
        "a1 = np.array([[1], [1]])\n",
        "a2 = np.array([[0], [1]])\n",
        "u = np.array([[4], [3]])\n",
        "\n",
        "A = np.column_stack((a1, a2))\n",
        "print (A)\n",
        "print ('---------')\n",
        "print (u)\n",
        "print ('---------')\n",
        "\n",
        "A_inv = np.linalg.inv(A)\n",
        "print (A_inv)\n",
        "\n",
        "x = A_inv @ u\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0]\n",
            " [1 1]]\n",
            "---------\n",
            "[[4]\n",
            " [3]]\n",
            "---------\n",
            "[[ 1.  0.]\n",
            " [-1.  1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.],\n",
              "       [-1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpdZ8JNso9_K"
      },
      "source": [
        "### Mapping Standard X Y Basis to New Basis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPGTKlj2o9_K"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h5furNnPNy9"
      },
      "source": [
        "![Capture81](https://drive.google.com/uc?id=1ehIzFIpVBJF_LOmWcmtc1EcUoCW2s_u-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFIEYmfbo9_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28753e4-88d1-4cf1-b802-0ccc3455e3e6"
      },
      "source": [
        "v = np.array([[-1], [-4]])\n",
        "print (v)\n",
        "print ('-------------------')\n",
        "\n",
        "# T = transformation / mapping matrix \n",
        "\n",
        "T = np.array([[-1/4, 1/4], [1/4, 1/4]])\n",
        "print(T)\n",
        "print ('-------------------')\n",
        "\n",
        "T_inv = np.linalg.inv(T)\n",
        "print (T_inv)\n",
        "print ('-------------------')\n",
        "\n",
        "print (T_inv @ v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1]\n",
            " [-4]]\n",
            "-------------------\n",
            "[[-0.25  0.25]\n",
            " [ 0.25  0.25]]\n",
            "-------------------\n",
            "[[-2.  2.]\n",
            " [ 2.  2.]]\n",
            "-------------------\n",
            "[[ -6.]\n",
            " [-10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnVjxkISo9_K"
      },
      "source": [
        "# Eigenvectors, Eigenvalues, Eigenspaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oywnU3d1o9_N"
      },
      "source": [
        "Think of ***eigenvectors*** as the dominant personality trait of someone and the ***eigenvalue*** as the intensity of that trait.  For an individual matrix, the eigenvector refers to the “characteristic vector” while eigenvalue refers to “characteristic value” for that vector.  \n",
        "\n",
        "***Eigenvector of a Matrix:*** Non-zero vector that does not rotate or change direction since it can only get longer or shorter when multiplied by a transformation matrix A.  There are infinitely many eigenvectors for each eigenvalue. <br>\n",
        "\n",
        "***Eigenvalue of a Matrix:*** scalar multiple of the eigenvector   \n",
        "\n",
        "Example: Donald Trump's dominant personality trait is fumbling narcissism.  This is his eigenvector.  No matter if he is developing NYC real estate or governing in the White House, his personality revolves around it.  The eigenvalue represents the scalar magnitude of his fumbling narcissism ... so off the charts. <br>\n",
        "\n",
        "Given square matrix A in $R^{nxn}$ space, eigenvector x, scalar λ, and identity matrix I: \n",
        "<center> $Ax = λx = λIx$ </center>\n",
        "<center> $Ax - λIx = 0$ </center>\n",
        "<center> $(A - λI)x = 0$ </center>\n",
        "<center> $... so (A - λI)$ must equal 0 </center> \n",
        "\n",
        "***(A - λI) is the eigenvalue*** of the matrix.  Determinant of a square matrix = scalar multiple of matrix = eigenvalue so:  \n",
        "<center> $det(A−λI)=0$ </center> \n",
        "\n",
        "Since matrix A and identity matrix I are fixed we need to solve for ***λ*** value that yields a 0 determinant of the matrix ***(A−λI)***. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwurZmno9_N"
      },
      "source": [
        "Step by Step Math Problem Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2utC96_YPY0f"
      },
      "source": [
        "![Capture82](https://drive.google.com/uc?id=1tr5wR0sM2LaNHXr6BddYR-Utd-OPQfJY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic43JUdpPhXS"
      },
      "source": [
        "![Capture83](https://drive.google.com/uc?id=1K6KbChT6yXAypYgKmvK3WLovPbxrymxL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQoUbXiGo9_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a0ce3c-2a96-40c4-b07f-73cca0b8f819"
      },
      "source": [
        "A = np.array([[-2, -4,  2],\n",
        "              [-2,  1,  2],\n",
        "              [4,   2,  5]])\n",
        "\n",
        "print (A)\n",
        "print ('-------------------------------------------------------')\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A) # must use this line of code exactly \n",
        "print(f'eigenvalues of matrix A are:{eigenvalues}')\n",
        "print ('-------------------------------------------------------')\n",
        "\n",
        "# code returns NORMALIZED eigenvectors \n",
        "print(f'normalized eigenvectors of matrix A are:\\n{eigenvectors}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2 -4  2]\n",
            " [-2  1  2]\n",
            " [ 4  2  5]]\n",
            "-------------------------------------------------------\n",
            "eigenvalues of matrix A are:[-5.  3.  6.]\n",
            "-------------------------------------------------------\n",
            "normalized eigenvectors of matrix A are:\n",
            "[[ 0.81649658  0.53452248  0.05842062]\n",
            " [ 0.40824829 -0.80178373  0.35052374]\n",
            " [-0.40824829 -0.26726124  0.93472998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dN1sm-go9_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892d4750-575f-42ed-cf4c-2bb89c03a131"
      },
      "source": [
        "# verify normalized eigenvectors are correct \n",
        "\n",
        "eigenvalue6_vector = np.array([[1], [6], [16]])\n",
        "print (eigenvalue6_vector)\n",
        "print ('----------------')\n",
        "\n",
        "eigenvalue6_normvector = eigenvalue6_vector * (1/(np.linalg.norm(eigenvalue6_vector, 2))) # denominator is Euclidean norm\n",
        "print (eigenvalue6_normvector) # equals column 3 of matrix A "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1]\n",
            " [ 6]\n",
            " [16]]\n",
            "----------------\n",
            "[[0.05842062]\n",
            " [0.35052374]\n",
            " [0.93472998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70rKmK7Wo9_O"
      },
      "source": [
        "# Trace & Determinant w/Eigenvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfNhMemro9_P"
      },
      "source": [
        "***Trace of Matrix:*** sum of matrix's diagonal elements.  Formula for square matrix $A∈R^{n×n}$: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqMcDDt4Pqkc"
      },
      "source": [
        "![Capture84](https://drive.google.com/uc?id=1m9R8wSmY0v9B2mG_yWZh3VzuD9HwtoSf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_nQqqfWo9_P"
      },
      "source": [
        "The sum of ***eigenvalues*** equals the trace of a matrix.  For example, see Matrix A from previous block of code:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuAXoFZOo9_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c5cad2-0746-4562-894a-3af4efa3bff4"
      },
      "source": [
        "A = np.array([[-2, -4,  2],\n",
        "              [-2,  1,  2],\n",
        "              [4,   2,  5]])\n",
        "\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2, -4,  2],\n",
              "       [-2,  1,  2],\n",
              "       [ 4,  2,  5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbnMvEabo9_P"
      },
      "source": [
        "The sum of Matrix A's diagonal elements are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFXnaM1go9_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3227185e-1d48-4fac-d74c-d9f65a7ddfc8"
      },
      "source": [
        "trace = A.trace()\n",
        "trace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAvg2X1uo9_Q"
      },
      "source": [
        "Trace value of 4 equals the sum of Matrix A's eigen values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czntsimbo9_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75299ed6-f0aa-4258-a2da-c243e9a3401d"
      },
      "source": [
        "print(f'eigenvalues of matrix A are:{eigenvalues}')\n",
        "\n",
        "np.round(sum(eigenvalues))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigenvalues of matrix A are:[-5.  3.  6.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u6wmtA1o9_Q"
      },
      "source": [
        "# Eigenvalue Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dofFJ1Ao9_Q"
      },
      "source": [
        "***Eigenvalue Decomposition (ED):*** Using the eigenvalue algorithm to find the eigenvalues and associated eigenvectors of a matrix; can only be performed on square matrices; decomposition may not be possible <br>\n",
        "\n",
        "The goal of ED  is to solve for eigenvalues and associated eigenvectors using a single matrix-matrix operation.  Given formula: \n",
        "<center> $Ax = λIx$ </center>\n",
        "\n",
        "The goal is to multiply a matrix of eigenvalues by the matrix of eigenvectors. Due to commutative property of multiplication (order matters), use formula: \n",
        "<center> $AX = XΛ$,  (Λ = λI)  </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3P-ayQGo9_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdba2405-4447-4aae-c1b3-868c26287cc0"
      },
      "source": [
        "# put normalized eigenvectors in matrix X\n",
        "X = eigenvectors\n",
        "print (X)\n",
        "print ('-------------')\n",
        "\n",
        "# put λI in matrix A\n",
        "I = np.identity(3)\n",
        "print (I)\n",
        "print ('-------------')\n",
        "\n",
        "E = eigenvalues * I \n",
        "print (E)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.81649658  0.53452248  0.05842062]\n",
            " [ 0.40824829 -0.80178373  0.35052374]\n",
            " [-0.40824829 -0.26726124  0.93472998]]\n",
            "-------------\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "-------------\n",
            "[[-5.  0.  0.]\n",
            " [-0.  3.  0.]\n",
            " [-0.  0.  6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAmp49GCo9_Q"
      },
      "source": [
        "Given formula ***AX = XΛ***, the left side of the equation ***AX*** equals:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZezAwF4o9_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34510918-231c-4e1d-d21d-080931772687"
      },
      "source": [
        "print(f'AX = \\n{A @ X}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AX = \n",
            "[[-4.0824829   1.60356745  0.35052374]\n",
            " [-2.04124145 -2.40535118  2.10314246]\n",
            " [ 2.04124145 -0.80178373  5.60837988]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmLdumV_o9_R"
      },
      "source": [
        "Given formula ***AX = XΛ***, the right side of the equation ***XΛ*** equals:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK3ujlCyo9_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04e61c0-93bc-448c-fffb-9d59f96205a0"
      },
      "source": [
        "print(f'XΛ = \\n{X @ E}') # order of multiplication matters!  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XΛ = \n",
            "[[-4.0824829   1.60356745  0.35052374]\n",
            " [-2.04124145 -2.40535118  2.10314246]\n",
            " [ 2.04124145 -0.80178373  5.60837988]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenNd--Wo9_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8768642-fa74-40da-9959-473402e5cdcf"
      },
      "source": [
        "# verify equality of matrices \n",
        "\n",
        "print (f'element wise equality? {np.allclose(A @ X, X @ E)}') # don't use equality operator for matrix comparison"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "element wise equality? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MS1TEtJo9_R"
      },
      "source": [
        "Final step of eigenvalue decomposition seeks to solve for matrix A.  Formula is: \n",
        "<center> $A=XΛX^{−1}$ </center>\n",
        "\n",
        "*** $X$:*** “axis” around which above matrix transformation occurs; eigenvectors matrix <br>\n",
        "*** $Λ$:*** matrix that can stretch, shrink, or flip the vectors <br>\n",
        "***$X^{−1}$:*** change basis (rotation) from standard basis into the eigenbasis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQkK_cRdo9_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573c8718-f315-4bee-ad31-70c5b5af14e2"
      },
      "source": [
        "X_inv = np.linalg.inv(X)\n",
        "\n",
        "print (f'matrix A: \\n{A}')\n",
        "print ('----------------')\n",
        "\n",
        "print (f'reconstruction of matrix A using  eigenvalue decomposition: \\n{X @ X @ E @ X_inv}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix A: \n",
            "[[-2 -4  2]\n",
            " [-2  1  2]\n",
            " [ 4  2  5]]\n",
            "----------------\n",
            "reconstruction of matrix A using  eigenvalue decomposition: \n",
            "[[-2.46835563 -2.61462259  2.99414125]\n",
            " [ 2.18916584 -1.7337294   0.96554784]\n",
            " [ 5.08993899  3.23519188  3.32263084]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFP-icsSPyKT"
      },
      "source": [
        "![Capture86](https://drive.google.com/uc?id=1OIQ-JvEtPJ1wjqdtGWOR4h3oQRFdkVE7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glLrA3Dto9_S"
      },
      "source": [
        "# Eigenbasis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukN1OSLJo9_S"
      },
      "source": [
        "***Eigenbasis:*** a set of linearly independent vectors (basis) in which every vector is an eigenvector; serves as a good basis that can simplify computations and improve understanding of the linear mapping(s). <br>\n",
        "\n",
        "In previous example using matrix A below, the eigenbasis equals: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOD3p_OCo9_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413b1d53-e861-4b61-a0d8-a42e056456f5"
      },
      "source": [
        "A = np.array([[-2, -4,  2],\n",
        "              [-2,  1,  2],\n",
        "              [4,   2,  5]])\n",
        "\n",
        "A\n",
        "\n",
        "# code returns NORMALIZED eigenvectors \n",
        "print(f'normalized eigenbasis:\\n{eigenvectors}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normalized eigenbasis:\n",
            "[[ 0.81649658  0.53452248  0.05842062]\n",
            " [ 0.40824829 -0.80178373  0.35052374]\n",
            " [-0.40824829 -0.26726124  0.93472998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixal3mggo9_S"
      },
      "source": [
        "# Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqidHzyko9_S"
      },
      "source": [
        "***Singular Value Decomposition (SVD):*** general decomposition method that can be used on all matrices including non-square and singular matrices.  SVD is used to reduce a dataset containing a large number of values to a dataset containing significantly fewer values, but which still contains a large fraction of the variability present in the original data.  \n",
        "\n",
        "For any rectangular matrix $A∈R^{m×n}$, it can be decomposed as the product of an orthogonal matrix $U∈R^{m×m}$, a diagonal matrix $Σ∈R^{m×m}$, and another orthogonal matrix $X^{−1}∈R^{n×n}$: \n",
        "<center> $A=UΣX^{−1}$ </center>\n",
        "<center> $A=UΣV^T$ </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1Fq9vxP5H5"
      },
      "source": [
        "![Capture87](https://drive.google.com/uc?id=1MVA6G4DQXgjIkIAU6XkohJ6xB2nDfIax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcmiV8jWo9_S"
      },
      "source": [
        "***Singular Values*** are the non-negative values along the diagonal of matrix Σ.  They can be viewed as akin to the eigenvalues in Eigenvalue Decomposition.\n",
        "\n",
        "There are two situations of note for matrix A with examples below: \n",
        "1. when m > n (more rows than columns)\n",
        "2. when m < n (more columns than rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQGKYxjTQBJL"
      },
      "source": [
        "![Capture88](https://drive.google.com/uc?id=12FJ65riDNoAG4L-hQlUTWYHm6IABmq-R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09AjHtZo9_T"
      },
      "source": [
        "Geometric interpretation of the SVD: sequence of linear mappings or transformations\n",
        "\n",
        "1. $V^T$ change basis (rotation) from the standard basis into a set of orthogonal basis \n",
        "2. $Σ$  scale (stretch, shrinks, or flip) the corresponding orthogonal basis \n",
        "3. $U$  change of basis (rotation) from the new orthogonal basis into a different orientation \n",
        "\n",
        "The main difference between SVD and Eigenvalue Decomposition is in matrix U.  Instead of going back to the standard basis, U performs a change of basis onto another direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqtsnM8go9_T"
      },
      "source": [
        "Illustrate effect of $A^{3x2}$ in a pair of vectors in standard basis. In the formula ***$A=UΣV^T$***, the right orthogonal matrix (U) has 3 column vectors ... it generates the third dimension which is orthogonal to the ellipse surface.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIr6RaxFQIfG"
      },
      "source": [
        "![Capture90](https://drive.google.com/uc?id=1W6aGwVzco6Kj2AWHS3Yxv9USLknvI1A-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJqef7zvo9_T"
      },
      "source": [
        "## 2x3 Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8NIy3tro9_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17e424d-7b34-4948-883e-b96f9f2a6d4f"
      },
      "source": [
        "# 2 x 3 matrix\n",
        "A_2x3 = np.array([[2, 1, 0],\n",
        "                   [-3, 0, 1]])\n",
        "\n",
        "print (A_2x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  1  0]\n",
            " [-3  0  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO2p70tXo9_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f333e4d0-99a5-47b9-f89c-5a70f2f1350b"
      },
      "source": [
        "# Decomposition of 2x3 matrix\n",
        "\n",
        "U1, S1, V_T1 = np.linalg.svd(A_2x3)\n",
        "\n",
        "print(f'Left orthogonal 2x3 matrix A:\\n{np.round(U1, 2)}\\n')\n",
        "print(f'Singular values diagonal 2x3 matrix A:\\n{np.round(S1, 2)}\\n')\n",
        "print(f'Right orthogonal 2x3 matrix A:\\n{np.round(V_T1, 2)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Left orthogonal 2x3 matrix A:\n",
            "[[-0.55  0.83]\n",
            " [ 0.83  0.55]]\n",
            "\n",
            "Singular values diagonal 2x3 matrix A:\n",
            "[3.74 1.  ]\n",
            "\n",
            "Right orthogonal 2x3 matrix A:\n",
            "[[-0.96 -0.15  0.22]\n",
            " [-0.    0.83  0.55]\n",
            " [ 0.27 -0.53  0.8 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SWyoTC2o9_T"
      },
      "source": [
        "## 3x2 Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmw4NjDKo9_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7eada5a-eb29-426e-a438-59a22923a7c9"
      },
      "source": [
        "# 3 x 2 matrix\n",
        "A_3x2 = np.array([[2, 1],\n",
        "                   [-3, 0],\n",
        "                   [0, 2]])\n",
        "\n",
        "print (A_3x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  1]\n",
            " [-3  0]\n",
            " [ 0  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XvXsInSo9_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6608f481-01db-4db3-b8b5-a6a947b931ef"
      },
      "source": [
        "# Decomposition of 3x2 matrix\n",
        "\n",
        "U2, S2, V_T2 = np.linalg.svd(A_3x2)\n",
        "\n",
        "print(f'Left orthogonal matrix for 3x2 matrix A:\\n{np.round(U2, 2)}\\n')\n",
        "print(f'Singular values diagonal matrix for 3x2 matrix A:\\n{np.round(S2, 2)}\\n')\n",
        "print(f'Right orthogonal matrix for 3x2 matrix A:\\n{np.round(V_T2, 2)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Left orthogonal matrix for 3x2 matrix A:\n",
            "[[-0.59 -0.24 -0.77]\n",
            " [ 0.8  -0.32 -0.51]\n",
            " [-0.13 -0.91  0.38]]\n",
            "\n",
            "Singular values diagonal matrix for 3x2 matrix A:\n",
            "[3.67 2.13]\n",
            "\n",
            "Right orthogonal matrix for 3x2 matrix A:\n",
            "[[-0.97 -0.23]\n",
            " [ 0.23 -0.97]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI_wSm_zo9_U"
      },
      "source": [
        "## 3x3 Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBd5lu3wo9_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cf674c-9a98-4340-8555-d87e4d2577b6"
      },
      "source": [
        "# 3 x 3 matrix: col 3 equals 2 x col 1\n",
        "A_3x3 = np.array([[2, 1, 4],\n",
        "                  [-3, 0, -6],\n",
        "                  [1, 2, 2]])\n",
        "\n",
        "print (A_3x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  1  4]\n",
            " [-3  0 -6]\n",
            " [ 1  2  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59UjM10Oo9_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ceaad7-b982-471f-a967-c901e37f0725"
      },
      "source": [
        "# Decomposition of 3x3 matrix\n",
        "\n",
        "U3, S3, V_T3 = np.linalg.svd(A_3x3)\n",
        "\n",
        "print(f'Left orthogonal matrix for 3x3 matrix A:\\n{np.round(U3, 2)}\\n')\n",
        "print(f'Singular values diagonal matrix for 3x3 matrix A:\\n{np.round(S3, 2)}')\n",
        "print (f'Note the third singular value equals 0 which means the third column contains redundant information. \\n')\n",
        "print(f'Right orthogonal matrix for 3x3 matrix A:\\n{np.round(V_T3, 2)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Left orthogonal matrix for 3x3 matrix A:\n",
            "[[-0.54 -0.2  -0.82]\n",
            " [ 0.79 -0.46 -0.41]\n",
            " [-0.29 -0.86  0.41]]\n",
            "\n",
            "Singular values diagonal matrix for 3x3 matrix A:\n",
            "[8.44 1.95 0.  ]\n",
            "Note the third singular value equals 0 which means the third column contains redundant information. \n",
            "\n",
            "Right orthogonal matrix for 3x3 matrix A:\n",
            "[[-0.44 -0.13 -0.89]\n",
            " [ 0.06 -0.99  0.12]\n",
            " [ 0.89  0.   -0.45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0rtEusUo9_U"
      },
      "source": [
        "# Matrix Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkUoXN8fo9_V"
      },
      "source": [
        "One common way to overcome the issue of real world applications with millions of rows and columns is to utilize low-rank approximations of the original matrices. Low rank means using a subset of orthogonal vectors instead of the full set of orthogonal vectors so that we can obtain a “reasonably” good approximation of the original matrix.  \n",
        "\n",
        "Low-rank approximations are possible because most data points can be computed as linear combinations of a subset of orthogonal vectors.  Specific examples include principal component analysis, factor analysis, and general dimensionality reduction techniques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLdU0jPgo9_V"
      },
      "source": [
        "# Matrix Decomposition Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFBShqUAo9_V"
      },
      "source": [
        "Important things to remember: \n",
        "1. LU Decomposition algorithm is used to solve Gaussian Elimination problems\n",
        "2. QR Decomposition algorithm is used to solve Gram-Schmidt Orthogonalization problems \n",
        "3. Eigenvalue Decomposition algorithm is used to solve for eigenvalues and associated eigenvectors of a square matrix using a single matrix-matrix operation\n",
        "4. Singular Value Decomposition algorithm is used to reduce a dataset containing a large number of values to a dataset containing significantly fewer values, but which still contains a large fraction of the variability present in the original data "
      ]
    }
  ]
}